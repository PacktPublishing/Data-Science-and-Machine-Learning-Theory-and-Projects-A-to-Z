{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'E:\\ML\\DNN\\time_series_covid_19_confirmed.csv')\n",
    "#df = pd.read_csv(r'E:\\convid\\time_series_covid_19_recovered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/2020</th>\n",
       "      <th>1/23/2020</th>\n",
       "      <th>1/24/2020</th>\n",
       "      <th>1/25/2020</th>\n",
       "      <th>1/26/2020</th>\n",
       "      <th>1/27/2020</th>\n",
       "      <th>...</th>\n",
       "      <th>3/5/2020</th>\n",
       "      <th>3/6/2020</th>\n",
       "      <th>3/7/2020</th>\n",
       "      <th>3/8/2020</th>\n",
       "      <th>3/9/2020</th>\n",
       "      <th>3/10/2020</th>\n",
       "      <th>3/11/2020</th>\n",
       "      <th>3/12/2020</th>\n",
       "      <th>3/13/2020</th>\n",
       "      <th>3/14/2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>138.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>360</td>\n",
       "      <td>420</td>\n",
       "      <td>461</td>\n",
       "      <td>502</td>\n",
       "      <td>511</td>\n",
       "      <td>581</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>701</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.2833</td>\n",
       "      <td>103.8333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>130</td>\n",
       "      <td>138</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>160</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>200</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>28.1667</td>\n",
       "      <td>84.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>112.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>99</td>\n",
       "      <td>117</td>\n",
       "      <td>129</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>197</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region      Lat      Long  1/22/2020  1/23/2020  \\\n",
       "0            NaN       Thailand  15.0000  101.0000          2          3   \n",
       "1            NaN          Japan  36.0000  138.0000          2          1   \n",
       "2            NaN      Singapore   1.2833  103.8333          0          1   \n",
       "3            NaN          Nepal  28.1667   84.2500          0          0   \n",
       "4            NaN       Malaysia   2.5000  112.5000          0          0   \n",
       "\n",
       "   1/24/2020  1/25/2020  1/26/2020  1/27/2020  ...  3/5/2020  3/6/2020  \\\n",
       "0          5          7          8          8  ...        47        48   \n",
       "1          2          2          4          4  ...       360       420   \n",
       "2          3          3          4          5  ...       117       130   \n",
       "3          0          1          1          1  ...         1         1   \n",
       "4          0          3          4          4  ...        50        83   \n",
       "\n",
       "   3/7/2020  3/8/2020  3/9/2020  3/10/2020  3/11/2020  3/12/2020  3/13/2020  \\\n",
       "0        50        50        50         53         59         70         75   \n",
       "1       461       502       511        581        639        639        701   \n",
       "2       138       150       150        160        178        178        200   \n",
       "3         1         1         1          1          1          1          1   \n",
       "4        93        99       117        129        149        149        197   \n",
       "\n",
       "   3/14/2020  \n",
       "0         82  \n",
       "1        773  \n",
       "2        212  \n",
       "3          1  \n",
       "4        238  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Province/State','Country/Region','Lat','Long'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 53 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   1/22/2020  442 non-null    int64\n",
      " 1   1/23/2020  442 non-null    int64\n",
      " 2   1/24/2020  442 non-null    int64\n",
      " 3   1/25/2020  442 non-null    int64\n",
      " 4   1/26/2020  442 non-null    int64\n",
      " 5   1/27/2020  442 non-null    int64\n",
      " 6   1/28/2020  442 non-null    int64\n",
      " 7   1/29/2020  442 non-null    int64\n",
      " 8   1/30/2020  442 non-null    int64\n",
      " 9   1/31/2020  442 non-null    int64\n",
      " 10  2/1/2020   442 non-null    int64\n",
      " 11  2/2/2020   442 non-null    int64\n",
      " 12  2/3/2020   442 non-null    int64\n",
      " 13  2/4/2020   442 non-null    int64\n",
      " 14  2/5/2020   442 non-null    int64\n",
      " 15  2/6/2020   442 non-null    int64\n",
      " 16  2/7/2020   442 non-null    int64\n",
      " 17  2/8/2020   442 non-null    int64\n",
      " 18  2/9/2020   442 non-null    int64\n",
      " 19  2/10/2020  442 non-null    int64\n",
      " 20  2/11/2020  442 non-null    int64\n",
      " 21  2/12/2020  442 non-null    int64\n",
      " 22  2/13/2020  442 non-null    int64\n",
      " 23  2/14/2020  442 non-null    int64\n",
      " 24  2/15/2020  442 non-null    int64\n",
      " 25  2/16/2020  442 non-null    int64\n",
      " 26  2/17/2020  442 non-null    int64\n",
      " 27  2/18/2020  442 non-null    int64\n",
      " 28  2/19/2020  442 non-null    int64\n",
      " 29  2/20/2020  442 non-null    int64\n",
      " 30  2/21/2020  442 non-null    int64\n",
      " 31  2/22/2020  442 non-null    int64\n",
      " 32  2/23/2020  442 non-null    int64\n",
      " 33  2/24/2020  442 non-null    int64\n",
      " 34  2/25/2020  442 non-null    int64\n",
      " 35  2/26/2020  442 non-null    int64\n",
      " 36  2/27/2020  442 non-null    int64\n",
      " 37  2/28/2020  442 non-null    int64\n",
      " 38  2/29/2020  442 non-null    int64\n",
      " 39  3/1/2020   442 non-null    int64\n",
      " 40  3/2/2020   442 non-null    int64\n",
      " 41  3/3/2020   442 non-null    int64\n",
      " 42  3/4/2020   442 non-null    int64\n",
      " 43  3/5/2020   442 non-null    int64\n",
      " 44  3/6/2020   442 non-null    int64\n",
      " 45  3/7/2020   442 non-null    int64\n",
      " 46  3/8/2020   442 non-null    int64\n",
      " 47  3/9/2020   442 non-null    int64\n",
      " 48  3/10/2020  442 non-null    int64\n",
      " 49  3/11/2020  442 non-null    int64\n",
      " 50  3/12/2020  442 non-null    int64\n",
      " 51  3/13/2020  442 non-null    int64\n",
      " 52  3/14/2020  442 non-null    int64\n",
      "dtypes: int64(53)\n",
      "memory usage: 183.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.copy()\n",
    "X = np.asarray(dataset.drop('3/14/2020', 1))\n",
    "y = np.asarray(dataset['3/14/2020'])\n",
    "sc = StandardScaler()\n",
    "X_normalized = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDims = X_normalized.shape[1]\n",
    "dnnModel = tf.keras.Sequential([    \n",
    "    layers.Dense(16, activation='relu', input_shape=(numDims,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(126, activation='relu'),\n",
    "    layers.Dense(160, activation='relu'),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
    "#optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "dnnModel.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 16)                848       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 126)               2142      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 160)               20320     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1610      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 25,203\n",
      "Trainable params: 25,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnnModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353 samples, validate on 89 samples\n",
      "Epoch 1/500\n",
      "353/353 [==============================] - 1s 3ms/sample - loss: 226998219062194.6250 - mae: 1285996.3750 - mse: 226998249062400.0000 - val_loss: 14664334167.6949 - val_mae: 13250.0762 - val_mse: 14664334336.0000\n",
      "Epoch 2/500\n",
      "353/353 [==============================] - 0s 195us/sample - loss: 220358355088381.9688 - mae: 1266906.5000 - mse: 220358347063296.0000 - val_loss: 14375154430.1612 - val_mae: 13117.6963 - val_mse: 14375153664.0000\n",
      "Epoch 3/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 214868280462924.9375 - mae: 1251212.7500 - mse: 214868288339968.0000 - val_loss: 14108404468.0058 - val_mae: 12994.5605 - val_mse: 14108404736.0000\n",
      "Epoch 4/500\n",
      "353/353 [==============================] - 0s 215us/sample - loss: 209631617258110.1875 - mae: 1236159.7500 - mse: 209631615909888.0000 - val_loss: 13856314048.2821 - val_mae: 12877.0381 - val_mse: 13856313344.0000\n",
      "Epoch 5/500\n",
      "353/353 [==============================] - 0s 269us/sample - loss: 204637143904317.2500 - mae: 1222199.6250 - mse: 204637156147200.0000 - val_loss: 13599625794.1554 - val_mae: 12756.3428 - val_mse: 13599625216.0000\n",
      "Epoch 6/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 199610025325969.7500 - mae: 1210099.2500 - mse: 199610014367744.0000 - val_loss: 13334382438.8250 - val_mae: 12630.3809 - val_mse: 13334381568.0000\n",
      "Epoch 7/500\n",
      "353/353 [==============================] - 0s 384us/sample - loss: 194607077383638.5000 - mae: 1193753.1250 - mse: 194607082110976.0000 - val_loss: 13100848513.3685 - val_mae: 12518.5449 - val_mse: 13100848128.0000\n",
      "Epoch 8/500\n",
      "353/353 [==============================] - 0s 256us/sample - loss: 190070325307362.9688 - mae: 1178823.8750 - mse: 190070321577984.0000 - val_loss: 12893723578.2511 - val_mae: 12418.4521 - val_mse: 12893723648.0000\n",
      "Epoch 9/500\n",
      "353/353 [==============================] - 0s 217us/sample - loss: 186028553375825.5312 - mae: 1168273.1250 - mse: 186028556025856.0000 - val_loss: 12646658178.1104 - val_mae: 12298.0156 - val_mse: 12646659072.0000\n",
      "Epoch 10/500\n",
      "353/353 [==============================] - 0s 272us/sample - loss: 181476478680249.8438 - mae: 1153748.0000 - mse: 181476477894656.0000 - val_loss: 12435743955.2277 - val_mae: 12194.3711 - val_mse: 12435744768.0000\n",
      "Epoch 11/500\n",
      "353/353 [==============================] - 0s 294us/sample - loss: 177352646233541.3438 - mae: 1140442.8750 - mse: 177352654979072.0000 - val_loss: 12199436144.7730 - val_mae: 12077.1309 - val_mse: 12199436288.0000\n",
      "Epoch 12/500\n",
      "353/353 [==============================] - 0s 385us/sample - loss: 172776337385057.8125 - mae: 1129918.7500 - mse: 172776333770752.0000 - val_loss: 11949765457.2288 - val_mae: 11951.8750 - val_mse: 11949765632.0000\n",
      "Epoch 13/500\n",
      "353/353 [==============================] - 0s 279us/sample - loss: 168205987299461.9062 - mae: 1114441.7500 - mse: 168206002028544.0000 - val_loss: 11736928572.8927 - val_mae: 11844.1855 - val_mse: 11736928256.0000\n",
      "Epoch 14/500\n",
      "353/353 [==============================] - 0s 281us/sample - loss: 164235197495060.6875 - mae: 1100848.3750 - mse: 164235187322880.0000 - val_loss: 11527821375.6726 - val_mae: 11737.4131 - val_mse: 11527821312.0000\n",
      "Epoch 15/500\n",
      "353/353 [==============================] - 0s 280us/sample - loss: 160365829426191.2500 - mae: 1087013.3750 - mse: 160365841219584.0000 - val_loss: 11329940064.2748 - val_mae: 11635.4512 - val_mse: 11329940480.0000\n",
      "Epoch 16/500\n",
      "353/353 [==============================] - 0s 263us/sample - loss: 156692285288959.1875 - mae: 1076238.3750 - mse: 156692302004224.0000 - val_loss: 11115517074.3413 - val_mae: 11524.0439 - val_mse: 11115517952.0000\n",
      "Epoch 17/500\n",
      "353/353 [==============================] - 0s 304us/sample - loss: 152753339389378.3438 - mae: 1062696.2500 - mse: 152753330454528.0000 - val_loss: 10904923916.8402 - val_mae: 11413.5508 - val_mse: 10904924160.0000\n",
      "Epoch 18/500\n",
      "353/353 [==============================] - 0s 293us/sample - loss: 148916460841903.9375 - mae: 1050459.2500 - mse: 148916448264192.0000 - val_loss: 10688164423.8908 - val_mae: 11298.6631 - val_mse: 10688163840.0000\n",
      "Epoch 19/500\n",
      "353/353 [==============================] - 0s 297us/sample - loss: 144961286783570.5000 - mae: 1039534.8750 - mse: 144961286701056.0000 - val_loss: 10466674503.3155 - val_mae: 11180.0010 - val_mse: 10466674688.0000\n",
      "Epoch 20/500\n",
      "353/353 [==============================] - 0s 301us/sample - loss: 141066662899085.4375 - mae: 1025934.8750 - mse: 141066674110464.0000 - val_loss: 10269787335.2902 - val_mae: 11073.5732 - val_mse: 10269787136.0000\n",
      "Epoch 21/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 137491217788640.5000 - mae: 1013594.3750 - mse: 137491222888448.0000 - val_loss: 10068896557.5643 - val_mae: 10963.9385 - val_mse: 10068896768.0000\n",
      "Epoch 22/500\n",
      "353/353 [==============================] - 0s 312us/sample - loss: 133966410216320.8125 - mae: 1000369.6875 - mse: 133966405304320.0000 - val_loss: 9878421684.1145 - val_mae: 10859.0156 - val_mse: 9878421504.0000\n",
      "Epoch 23/500\n",
      "353/353 [==============================] - 0s 253us/sample - loss: 130647650485895.1406 - mae: 987418.9375 - mse: 130647670652928.0000 - val_loss: 9712205658.9296 - val_mae: 10766.7070 - val_mse: 9712205824.0000\n",
      "Epoch 24/500\n",
      "353/353 [==============================] - 0s 262us/sample - loss: 127615885561322.1094 - mae: 978218.6875 - mse: 127615885115392.0000 - val_loss: 9510655850.0204 - val_mae: 10653.5840 - val_mse: 9510656000.0000\n",
      "Epoch 25/500\n",
      "353/353 [==============================] - 0s 359us/sample - loss: 124182506938841.4688 - mae: 963787.6250 - mse: 124182494969856.0000 - val_loss: 9349901436.8109 - val_mae: 10562.5566 - val_mse: 9349902336.0000\n",
      "Epoch 26/500\n",
      "353/353 [==============================] - 0s 298us/sample - loss: 121340850689409.3281 - mae: 955248.5625 - mse: 121340854009856.0000 - val_loss: 9155579808.1002 - val_mae: 10451.4385 - val_mse: 9155579904.0000\n",
      "Epoch 27/500\n",
      "353/353 [==============================] - 0s 271us/sample - loss: 118022087871177.6094 - mae: 941615.9375 - mse: 118022085804032.0000 - val_loss: 8981769655.1805 - val_mae: 10351.1035 - val_mse: 8981770240.0000\n",
      "Epoch 28/500\n",
      "353/353 [==============================] - 0s 368us/sample - loss: 114955218923583.5000 - mae: 931354.8125 - mse: 114955210719232.0000 - val_loss: 8798817512.1745 - val_mae: 10244.3760 - val_mse: 8798817280.0000\n",
      "Epoch 29/500\n",
      "353/353 [==============================] - 0s 218us/sample - loss: 111904865750192.9531 - mae: 916601.1875 - mse: 111904836026368.0000 - val_loss: 8656762320.1327 - val_mae: 10160.6162 - val_mse: 8656762880.0000\n",
      "Epoch 30/500\n",
      "353/353 [==============================] - 0s 296us/sample - loss: 109440675230456.4062 - mae: 908293.2500 - mse: 109440674037760.0000 - val_loss: 8484153183.7005 - val_mae: 10058.1084 - val_mse: 8484152832.0000\n",
      "Epoch 31/500\n",
      "353/353 [==============================] - 0s 313us/sample - loss: 106525738674992.9688 - mae: 896452.2500 - mse: 106525741809664.0000 - val_loss: 8317915816.1290 - val_mae: 9958.3916 - val_mse: 8317916160.0000\n",
      "Epoch 32/500\n",
      "353/353 [==============================] - 0s 297us/sample - loss: 103700161943319.6875 - mae: 886052.3750 - mse: 103700156645376.0000 - val_loss: 8147573201.7361 - val_mae: 9855.1230 - val_mse: 8147573248.0000\n",
      "Epoch 33/500\n",
      "353/353 [==============================] - 0s 268us/sample - loss: 100862106014162.9062 - mae: 874060.6250 - mse: 100862097620992.0000 - val_loss: 7995840018.9231 - val_mae: 9762.2559 - val_mse: 7995839488.0000\n",
      "Epoch 34/500\n",
      "353/353 [==============================] - 0s 259us/sample - loss: 98355055995673.2812 - mae: 863232.8125 - mse: 98355061456896.0000 - val_loss: 7844198158.7937 - val_mae: 9668.5947 - val_mse: 7844198400.0000\n",
      "Epoch 35/500\n",
      "353/353 [==============================] - 0s 295us/sample - loss: 95841616913850.9531 - mae: 851557.5000 - mse: 95841616396288.0000 - val_loss: 7700729222.8744 - val_mae: 9579.1680 - val_mse: 7700729856.0000\n",
      "Epoch 36/500\n",
      "353/353 [==============================] - 0s 236us/sample - loss: 93432683452819.6719 - mae: 842250.4375 - mse: 93432685002752.0000 - val_loss: 7543275964.3980 - val_mae: 9479.9961 - val_mse: 7543276032.0000\n",
      "Epoch 37/500\n",
      "353/353 [==============================] - 0s 398us/sample - loss: 90791404075222.6719 - mae: 833105.0625 - mse: 90791405944832.0000 - val_loss: 7376989244.4810 - val_mae: 9374.0234 - val_mse: 7376989696.0000\n",
      "Epoch 38/500\n",
      "353/353 [==============================] - 0s 191us/sample - loss: 88178394254616.9688 - mae: 820097.8750 - mse: 88178404884480.0000 - val_loss: 7244775650.7663 - val_mae: 9289.0381 - val_mse: 7244775936.0000\n",
      "Epoch 39/500\n",
      "353/353 [==============================] - 0s 195us/sample - loss: 86060202891430.7031 - mae: 810091.2500 - mse: 86060197478400.0000 - val_loss: 7110601870.4093 - val_mae: 9202.0459 - val_mse: 7110602240.0000\n",
      "Epoch 40/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 83778198758037.6562 - mae: 802201.7500 - mse: 83778194112512.0000 - val_loss: 6955655930.9137 - val_mae: 9100.3945 - val_mse: 6955656192.0000\n",
      "Epoch 41/500\n",
      "353/353 [==============================] - 0s 300us/sample - loss: 81366927544366.8438 - mae: 791094.5000 - mse: 81366930685952.0000 - val_loss: 6817079424.1270 - val_mae: 9008.6504 - val_mse: 6817079808.0000\n",
      "Epoch 42/500\n",
      "353/353 [==============================] - 0s 282us/sample - loss: 79092698402787.0000 - mae: 780659.7500 - mse: 79092695171072.0000 - val_loss: 6682557337.5839 - val_mae: 8918.6660 - val_mse: 6682556928.0000\n",
      "Epoch 43/500\n",
      "353/353 [==============================] - 0s 209us/sample - loss: 77017627244555.6094 - mae: 770212.2500 - mse: 77017630375936.0000 - val_loss: 6538034005.4816 - val_mae: 8821.2061 - val_mse: 6538034176.0000\n",
      "Epoch 44/500\n",
      "353/353 [==============================] - 0s 256us/sample - loss: 74719137013039.2812 - mae: 758176.9375 - mse: 74719135006720.0000 - val_loss: 6404474393.0204 - val_mae: 8730.1260 - val_mse: 6404474880.0000\n",
      "Epoch 45/500\n",
      "353/353 [==============================] - 0s 217us/sample - loss: 72655025177606.3125 - mae: 749277.8125 - mse: 72655025733632.0000 - val_loss: 6259211710.2162 - val_mae: 8629.8633 - val_mse: 6259211776.0000\n",
      "Epoch 46/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 70412725030900.3906 - mae: 739730.5000 - mse: 70412725649408.0000 - val_loss: 6098289853.2186 - val_mae: 8517.3770 - val_mse: 6098290176.0000\n",
      "Epoch 47/500\n",
      "353/353 [==============================] - 0s 195us/sample - loss: 68069715442764.8594 - mae: 728035.9375 - mse: 68069711937536.0000 - val_loss: 6090742112.0873 - val_mae: 8512.0664 - val_mse: 6090742272.0000\n",
      "Epoch 48/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 67952359152631.2969 - mae: 727270.1250 - mse: 67952351117312.0000 - val_loss: 6080812597.2870 - val_mae: 8505.0645 - val_mse: 6080812544.0000\n",
      "Epoch 49/500\n",
      "353/353 [==============================] - 0s 260us/sample - loss: 67794634700600.7344 - mae: 726355.9375 - mse: 67794628509696.0000 - val_loss: 6058225342.3801 - val_mae: 8489.1406 - val_mse: 6058225152.0000\n",
      "Epoch 50/500\n",
      "353/353 [==============================] - 0s 216us/sample - loss: 67439995807733.0547 - mae: 724843.3125 - mse: 67439995912192.0000 - val_loss: 6011769566.8235 - val_mae: 8456.3213 - val_mse: 6011769856.0000\n",
      "Epoch 51/500\n",
      "353/353 [==============================] - 0s 224us/sample - loss: 66719352992405.3906 - mae: 721246.6250 - mse: 66719355764736.0000 - val_loss: 5933833830.1329 - val_mae: 8400.9619 - val_mse: 5933834240.0000\n",
      "Epoch 52/500\n",
      "353/353 [==============================] - 0s 268us/sample - loss: 65503130057522.1250 - mae: 714753.8750 - mse: 65503129239552.0000 - val_loss: 5829676152.9256 - val_mae: 8326.4238 - val_mse: 5829676032.0000\n",
      "Epoch 53/500\n",
      "353/353 [==============================] - 0s 230us/sample - loss: 63898935833718.4844 - mae: 707056.1875 - mse: 63898933788672.0000 - val_loss: 5708502548.7921 - val_mae: 8238.8047 - val_mse: 5708502528.0000\n",
      "Epoch 54/500\n",
      "353/353 [==============================] - 0s 220us/sample - loss: 62091163075278.9609 - mae: 697262.2500 - mse: 62091163598848.0000 - val_loss: 5592308617.3046 - val_mae: 8153.9277 - val_mse: 5592308736.0000\n",
      "Epoch 55/500\n",
      "353/353 [==============================] - 0s 316us/sample - loss: 60359090043344.2266 - mae: 687791.9375 - mse: 60359092207616.0000 - val_loss: 5472289635.2884 - val_mae: 8065.3018 - val_mse: 5472289280.0000\n",
      "Epoch 56/500\n",
      "353/353 [==============================] - 0s 212us/sample - loss: 58621730296199.6172 - mae: 676839.1250 - mse: 58621727604736.0000 - val_loss: 5369500489.1101 - val_mae: 7988.6343 - val_mse: 5369500160.0000\n",
      "Epoch 57/500\n",
      "353/353 [==============================] - 0s 236us/sample - loss: 57043402820792.2031 - mae: 670657.0625 - mse: 57043406815232.0000 - val_loss: 5240405067.3051 - val_mae: 7891.2163 - val_mse: 5240404992.0000\n",
      "Epoch 58/500\n",
      "353/353 [==============================] - 0s 262us/sample - loss: 55216643126129.6250 - mae: 659272.1250 - mse: 55216640622592.0000 - val_loss: 5124492440.1035 - val_mae: 7802.8188 - val_mse: 5124492288.0000\n",
      "Epoch 59/500\n",
      "353/353 [==============================] - 0s 263us/sample - loss: 53551880546646.3047 - mae: 649688.2500 - mse: 53551883616256.0000 - val_loss: 5018893698.7733 - val_mae: 7721.3794 - val_mse: 5018893312.0000\n",
      "Epoch 60/500\n",
      "353/353 [==============================] - 0s 273us/sample - loss: 51985318796620.7578 - mae: 642462.7500 - mse: 51985315266560.0000 - val_loss: 4897705749.0305 - val_mae: 7626.8433 - val_mse: 4897705984.0000\n",
      "Epoch 61/500\n",
      "353/353 [==============================] - 0s 346us/sample - loss: 50348694025787.6953 - mae: 631359.5625 - mse: 50348693651456.0000 - val_loss: 4802219155.2108 - val_mae: 7551.6167 - val_mse: 4802219008.0000\n",
      "Epoch 62/500\n",
      "353/353 [==============================] - 0s 277us/sample - loss: 48943760949143.5703 - mae: 623760.4375 - mse: 48943765389312.0000 - val_loss: 4692704069.2274 - val_mae: 7464.3447 - val_mse: 4692704256.0000\n",
      "Epoch 63/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 47379806176438.3906 - mae: 615737.3750 - mse: 47379805896704.0000 - val_loss: 4579947501.3296 - val_mae: 7373.3843 - val_mse: 4579947520.0000\n",
      "Epoch 64/500\n",
      "353/353 [==============================] - 0s 243us/sample - loss: 45839396927586.6250 - mae: 605244.5625 - mse: 45839397421056.0000 - val_loss: 4485968226.7269 - val_mae: 7296.6826 - val_mse: 4485968384.0000\n",
      "Epoch 65/500\n",
      "353/353 [==============================] - 0s 326us/sample - loss: 44515982485895.5234 - mae: 597922.2500 - mse: 44515981262848.0000 - val_loss: 4383225863.1806 - val_mae: 7211.9868 - val_mse: 4383225856.0000\n",
      "Epoch 66/500\n",
      "353/353 [==============================] - 0s 252us/sample - loss: 43134075785656.3516 - mae: 588326.4375 - mse: 43134075535360.0000 - val_loss: 4284920841.0106 - val_mae: 7130.0464 - val_mse: 4284920832.0000\n",
      "Epoch 67/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 41798787029341.1562 - mae: 579050.1250 - mse: 41798789496832.0000 - val_loss: 4197603845.1092 - val_mae: 7056.4473 - val_mse: 4197604096.0000\n",
      "Epoch 68/500\n",
      "353/353 [==============================] - 0s 190us/sample - loss: 40611060004281.0781 - mae: 571467.5000 - mse: 40611059073024.0000 - val_loss: 4103967381.1117 - val_mae: 6976.7197 - val_mse: 4103967488.0000\n",
      "Epoch 69/500\n",
      "353/353 [==============================] - 0s 289us/sample - loss: 39302273211189.9453 - mae: 564576.0625 - mse: 39302276841472.0000 - val_loss: 4002201074.4131 - val_mae: 6888.9502 - val_mse: 4002201088.0000\n",
      "Epoch 70/500\n",
      "353/353 [==============================] - 0s 302us/sample - loss: 37984260607617.0938 - mae: 555027.5625 - mse: 37984258752512.0000 - val_loss: 3913126373.3285 - val_mae: 6811.1646 - val_mse: 3913126656.0000\n",
      "Epoch 71/500\n",
      "353/353 [==============================] - 0s 343us/sample - loss: 36776870555372.5234 - mae: 548301.7500 - mse: 36776869625856.0000 - val_loss: 3815467884.9199 - val_mae: 6724.9219 - val_mse: 3815468032.0000\n",
      "Epoch 72/500\n",
      "353/353 [==============================] - 0s 354us/sample - loss: 35541225397257.0703 - mae: 537787.0000 - mse: 35541227667456.0000 - val_loss: 3740062333.6685 - val_mae: 6657.5947 - val_mse: 3740062464.0000\n",
      "Epoch 73/500\n",
      "353/353 [==============================] - 0s 288us/sample - loss: 34541905815425.4727 - mae: 531564.6875 - mse: 34541903282176.0000 - val_loss: 3652789906.4357 - val_mae: 6578.8286 - val_mse: 3652790016.0000\n",
      "Epoch 74/500\n",
      "353/353 [==============================] - 0s 334us/sample - loss: 33422504648171.2539 - mae: 522847.5312 - mse: 33422504361984.0000 - val_loss: 3574169766.5177 - val_mae: 6507.0913 - val_mse: 3574169856.0000\n",
      "Epoch 75/500\n",
      "353/353 [==============================] - 0s 198us/sample - loss: 32365672996861.6836 - mae: 517320.8750 - mse: 32365671874560.0000 - val_loss: 3481151482.7421 - val_mae: 6421.0967 - val_mse: 3481151232.0000\n",
      "Epoch 76/500\n",
      "353/353 [==============================] - 0s 271us/sample - loss: 31229784048133.8477 - mae: 507449.8438 - mse: 31229789339648.0000 - val_loss: 3409978933.6365 - val_mae: 6354.5869 - val_mse: 3409979136.0000\n",
      "Epoch 77/500\n",
      "353/353 [==============================] - 0s 277us/sample - loss: 30310426887195.8516 - mae: 502102.3438 - mse: 30310427262976.0000 - val_loss: 3324699853.6158 - val_mae: 6273.9585 - val_mse: 3324699904.0000\n",
      "Epoch 78/500\n",
      "353/353 [==============================] - 0s 451us/sample - loss: 29245714459930.1055 - mae: 493177.4688 - mse: 29245715775488.0000 - val_loss: 3249588133.2050 - val_mae: 6202.1348 - val_mse: 3249588224.0000\n",
      "Epoch 79/500\n",
      "353/353 [==============================] - 0s 231us/sample - loss: 28313273241245.8320 - mae: 485559.5312 - mse: 28313273761792.0000 - val_loss: 3177128426.4809 - val_mae: 6132.0356 - val_mse: 3177128704.0000\n",
      "Epoch 80/500\n",
      "353/353 [==============================] - 0s 204us/sample - loss: 27422184496042.3320 - mae: 479085.5000 - mse: 27422185488384.0000 - val_loss: 3103655119.6268 - val_mae: 6060.1602 - val_mse: 3103655424.0000\n",
      "Epoch 81/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 26508078524135.3438 - mae: 471011.7500 - mse: 26508078874624.0000 - val_loss: 3035235661.6594 - val_mae: 5992.4375 - val_mse: 3035235584.0000\n",
      "Epoch 82/500\n",
      "353/353 [==============================] - 0s 206us/sample - loss: 25670610027208.7109 - mae: 464671.3125 - mse: 25670608486400.0000 - val_loss: 2960729786.4658 - val_mae: 5917.8076 - val_mse: 2960729856.0000\n",
      "Epoch 83/500\n",
      "353/353 [==============================] - 0s 249us/sample - loss: 24772992136209.4023 - mae: 457500.3750 - mse: 24772991778816.0000 - val_loss: 2887086561.9077 - val_mae: 5843.1035 - val_mse: 2887086592.0000\n",
      "Epoch 84/500\n",
      "353/353 [==============================] - 0s 285us/sample - loss: 23906753251369.4375 - mae: 449269.8125 - mse: 23906754756608.0000 - val_loss: 2825917903.4512 - val_mae: 5780.3550 - val_mse: 2825917952.0000\n",
      "Epoch 85/500\n",
      "353/353 [==============================] - 0s 299us/sample - loss: 23160005931629.6875 - mae: 443728.3750 - mse: 23160005066752.0000 - val_loss: 2755469031.4040 - val_mae: 5707.2183 - val_mse: 2755469056.0000\n",
      "Epoch 86/500\n",
      "353/353 [==============================] - 0s 295us/sample - loss: 22332849022328.6797 - mae: 437447.3438 - mse: 22332848472064.0000 - val_loss: 2683742015.7544 - val_mae: 5631.7793 - val_mse: 2683741952.0000\n",
      "Epoch 87/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 21528040799420.5547 - mae: 429787.3438 - mse: 21528039129088.0000 - val_loss: 2621582576.4366 - val_mae: 5565.5557 - val_mse: 2621582592.0000\n",
      "Epoch 88/500\n",
      "353/353 [==============================] - 0s 249us/sample - loss: 20791962134498.9922 - mae: 423272.0625 - mse: 20791961845760.0000 - val_loss: 2555740224.1224 - val_mae: 5494.6240 - val_mse: 2555740160.0000\n",
      "Epoch 89/500\n",
      "353/353 [==============================] - 0s 315us/sample - loss: 20070317880782.6875 - mae: 415270.9375 - mse: 20070315065344.0000 - val_loss: 2502926357.9796 - val_mae: 5437.0469 - val_mse: 2502926336.0000\n",
      "Epoch 90/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 19466363155713.9141 - mae: 410191.8125 - mse: 19466362552320.0000 - val_loss: 2440918076.0110 - val_mae: 5368.7227 - val_mse: 2440918016.0000\n",
      "Epoch 91/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 18748258155718.7773 - mae: 404370.5312 - mse: 18748259958784.0000 - val_loss: 2375429364.7291 - val_mae: 5295.5605 - val_mse: 2375429376.0000\n",
      "Epoch 92/500\n",
      "353/353 [==============================] - 0s 197us/sample - loss: 18049543559136.8164 - mae: 396942.5625 - mse: 18049545535488.0000 - val_loss: 2318863549.3833 - val_mae: 5231.5854 - val_mse: 2318863616.0000\n",
      "Epoch 93/500\n",
      "353/353 [==============================] - 0s 322us/sample - loss: 17418786052159.0938 - mae: 391171.9062 - mse: 17418786177024.0000 - val_loss: 2258538593.5634 - val_mae: 5162.4580 - val_mse: 2258538752.0000\n",
      "Epoch 94/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 16783078573157.8926 - mae: 383868.4688 - mse: 16783080685568.0000 - val_loss: 2205901651.6840 - val_mae: 5101.4248 - val_mse: 2205901568.0000\n",
      "Epoch 95/500\n",
      "353/353 [==============================] - 0s 282us/sample - loss: 16219917180545.0879 - mae: 378572.7500 - mse: 16219916730368.0000 - val_loss: 2151543827.7138 - val_mae: 5037.6201 - val_mse: 2151543808.0000\n",
      "Epoch 96/500\n",
      "353/353 [==============================] - 0s 294us/sample - loss: 15635787241551.5254 - mae: 371406.5625 - mse: 15635785449472.0000 - val_loss: 2102416215.9197 - val_mae: 4979.2842 - val_mse: 2102416256.0000\n",
      "Epoch 97/500\n",
      "353/353 [==============================] - 0s 319us/sample - loss: 15115612574308.4766 - mae: 366180.7500 - mse: 15115611013120.0000 - val_loss: 2050741703.1110 - val_mae: 4917.1582 - val_mse: 2050741632.0000\n",
      "Epoch 98/500\n",
      "353/353 [==============================] - 0s 297us/sample - loss: 14576856172303.1641 - mae: 360649.8438 - mse: 14576855810048.0000 - val_loss: 1997139573.2734 - val_mae: 4851.8633 - val_mse: 1997139584.0000\n",
      "Epoch 99/500\n",
      "353/353 [==============================] - 0s 435us/sample - loss: 14052165276275.2402 - mae: 354301.5000 - mse: 14052166205440.0000 - val_loss: 1951005100.8924 - val_mae: 4795.0190 - val_mse: 1951005056.0000\n",
      "Epoch 100/500\n",
      "353/353 [==============================] - 0s 315us/sample - loss: 13573502106885.2402 - mae: 348329.3750 - mse: 13573500698624.0000 - val_loss: 1903976312.2564 - val_mae: 4736.3433 - val_mse: 1903976320.0000\n",
      "Epoch 101/500\n",
      "353/353 [==============================] - 0s 192us/sample - loss: 13081796855132.5957 - mae: 343678.5000 - mse: 13081798246400.0000 - val_loss: 1849479505.9160 - val_mae: 4667.4146 - val_mse: 1849479552.0000\n",
      "Epoch 102/500\n",
      "353/353 [==============================] - 0s 330us/sample - loss: 12568554628525.2773 - mae: 337525.5312 - mse: 12568555945984.0000 - val_loss: 1801475592.1013 - val_mae: 4605.8896 - val_mse: 1801475712.0000\n",
      "Epoch 103/500\n",
      "353/353 [==============================] - 0s 367us/sample - loss: 12092052928449.0195 - mae: 332372.8125 - mse: 12092052602880.0000 - val_loss: 1750640174.6538 - val_mae: 4539.8120 - val_mse: 1750640128.0000\n",
      "Epoch 104/500\n",
      "353/353 [==============================] - 0s 221us/sample - loss: 11632348516918.3906 - mae: 325242.3125 - mse: 11632347447296.0000 - val_loss: 1712634057.2926 - val_mae: 4489.8096 - val_mse: 1712634112.0000\n",
      "Epoch 105/500\n",
      "353/353 [==============================] - 0s 292us/sample - loss: 11251765264153.0996 - mae: 321806.7188 - mse: 11251764690944.0000 - val_loss: 1662819977.1981 - val_mae: 4423.3706 - val_mse: 1662819840.0000\n",
      "Epoch 106/500\n",
      "353/353 [==============================] - 0s 257us/sample - loss: 10819944015658.6973 - mae: 315682.5625 - mse: 10819944316928.0000 - val_loss: 1620475393.3883 - val_mae: 4366.1729 - val_mse: 1620475520.0000\n",
      "Epoch 107/500\n",
      "353/353 [==============================] - 0s 334us/sample - loss: 10453733015059.0273 - mae: 310334.6562 - mse: 10453733343232.0000 - val_loss: 1581458258.2112 - val_mae: 4312.8535 - val_mse: 1581458176.0000\n",
      "Epoch 108/500\n",
      "353/353 [==============================] - 0s 325us/sample - loss: 10084985621320.9297 - mae: 306265.9375 - mse: 10084985864192.0000 - val_loss: 1536773879.5985 - val_mae: 4250.9033 - val_mse: 1536773760.0000\n",
      "Epoch 109/500\n",
      "353/353 [==============================] - 0s 321us/sample - loss: 9709317308698.7344 - mae: 300123.0625 - mse: 9709317783552.0000 - val_loss: 1498318403.0333 - val_mae: 4196.8872 - val_mse: 1498318464.0000\n",
      "Epoch 110/500\n",
      "353/353 [==============================] - 0s 316us/sample - loss: 9378019629604.2617 - mae: 295263.3438 - mse: 9378018099200.0000 - val_loss: 1463321442.2996 - val_mae: 4147.1206 - val_mse: 1463321344.0000\n",
      "Epoch 111/500\n",
      "353/353 [==============================] - 0s 346us/sample - loss: 9071079338134.7637 - mae: 290744.6875 - mse: 9071079981056.0000 - val_loss: 1426006414.3392 - val_mae: 4093.4529 - val_mse: 1426006528.0000\n",
      "Epoch 112/500\n",
      "353/353 [==============================] - 0s 312us/sample - loss: 8744783348511.5654 - mae: 286244.0938 - mse: 8744783052800.0000 - val_loss: 1385529533.2515 - val_mae: 4034.4128 - val_mse: 1385529472.0000\n",
      "Epoch 113/500\n",
      "353/353 [==============================] - 0s 305us/sample - loss: 8412673636684.1465 - mae: 280921.2500 - mse: 8412674392064.0000 - val_loss: 1350143684.3646 - val_mae: 3982.0786 - val_mse: 1350143616.0000\n",
      "Epoch 114/500\n",
      "353/353 [==============================] - 0s 274us/sample - loss: 8117091011676.8281 - mae: 276662.4062 - mse: 8117089730560.0000 - val_loss: 1312907263.6515 - val_mae: 3926.2698 - val_mse: 1312907264.0000\n",
      "Epoch 115/500\n",
      "353/353 [==============================] - 0s 390us/sample - loss: 7796411957948.8027 - mae: 272643.1562 - mse: 7796412121088.0000 - val_loss: 1270452509.7387 - val_mae: 3861.6221 - val_mse: 1270452608.0000\n",
      "Epoch 116/500\n",
      "353/353 [==============================] - 0s 230us/sample - loss: 7484022256673.3604 - mae: 266492.0000 - mse: 7484022456320.0000 - val_loss: 1239054626.5652 - val_mae: 3813.1917 - val_mse: 1239054592.0000\n",
      "Epoch 117/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 7221490917544.2637 - mae: 263099.7500 - mse: 7221491007488.0000 - val_loss: 1202486647.4351 - val_mae: 3756.0242 - val_mse: 1202486656.0000\n",
      "Epoch 118/500\n",
      "353/353 [==============================] - 0s 281us/sample - loss: 6942075680360.9941 - mae: 257587.4844 - mse: 6942076436480.0000 - val_loss: 1172211814.9007 - val_mae: 3708.0659 - val_mse: 1172211840.0000\n",
      "Epoch 119/500\n",
      "353/353 [==============================] - 0s 254us/sample - loss: 6686309178827.3066 - mae: 254334.9844 - mse: 6686308827136.0000 - val_loss: 1135900552.5891 - val_mae: 3649.6885 - val_mse: 1135900544.0000\n",
      "Epoch 120/500\n",
      "353/353 [==============================] - 0s 259us/sample - loss: 6417000740002.4707 - mae: 248496.5469 - mse: 6417000431616.0000 - val_loss: 1108386161.7226 - val_mae: 3604.8440 - val_mse: 1108386176.0000\n",
      "Epoch 121/500\n",
      "353/353 [==============================] - 0s 324us/sample - loss: 6191768512192.2432 - mae: 245667.8125 - mse: 6191768928256.0000 - val_loss: 1075097027.5664 - val_mae: 3549.8091 - val_mse: 1075097088.0000\n",
      "Epoch 122/500\n",
      "353/353 [==============================] - 0s 291us/sample - loss: 5944437858878.2549 - mae: 241136.8125 - mse: 5944437637120.0000 - val_loss: 1044560143.5325 - val_mae: 3498.5730 - val_mse: 1044560064.0000\n",
      "Epoch 123/500\n",
      "353/353 [==============================] - 0s 308us/sample - loss: 5731238606075.2197 - mae: 236338.6250 - mse: 5731239067648.0000 - val_loss: 1019830682.2356 - val_mae: 3456.5793 - val_mse: 1019830656.0000\n",
      "Epoch 124/500\n",
      "353/353 [==============================] - 0s 316us/sample - loss: 5541307002178.4922 - mae: 233236.7188 - mse: 5541306826752.0000 - val_loss: 990024457.5314 - val_mae: 3405.2590 - val_mse: 990024448.0000\n",
      "Epoch 125/500\n",
      "353/353 [==============================] - 0s 279us/sample - loss: 5337164244642.0762 - mae: 228518.5469 - mse: 5337164808192.0000 - val_loss: 964328520.4255 - val_mae: 3360.4077 - val_mse: 964328448.0000\n",
      "Epoch 126/500\n",
      "353/353 [==============================] - 0s 270us/sample - loss: 5152866105750.4932 - mae: 225418.2188 - mse: 5152866041856.0000 - val_loss: 934379535.8037 - val_mae: 3307.3669 - val_mse: 934379520.0000\n",
      "Epoch 127/500\n",
      "353/353 [==============================] - 0s 478us/sample - loss: 4947714827207.6338 - mae: 221578.4219 - mse: 4947714768896.0000 - val_loss: 905058853.1943 - val_mae: 3254.6018 - val_mse: 905058880.0000\n",
      "Epoch 128/500\n",
      "353/353 [==============================] - 0s 329us/sample - loss: 4751971695385.0703 - mae: 217183.3125 - mse: 4751971844096.0000 - val_loss: 877623629.3738 - val_mae: 3204.4685 - val_mse: 877623680.0000\n",
      "Epoch 129/500\n",
      "353/353 [==============================] - 0s 272us/sample - loss: 4576600481029.3926 - mae: 213262.0312 - mse: 4576600653824.0000 - val_loss: 855033675.8532 - val_mae: 3162.6360 - val_mse: 855033664.0000\n",
      "Epoch 130/500\n",
      "353/353 [==============================] - 0s 270us/sample - loss: 4422228495665.2461 - mae: 209574.5781 - mse: 4422228770816.0000 - val_loss: 832341276.4039 - val_mae: 3120.0540 - val_mse: 832341248.0000\n",
      "Epoch 131/500\n",
      "353/353 [==============================] - 0s 261us/sample - loss: 4257221415909.8926 - mae: 206839.5469 - mse: 4257221443584.0000 - val_loss: 803707068.1363 - val_mae: 3065.3708 - val_mse: 803707072.0000\n",
      "Epoch 132/500\n",
      "353/353 [==============================] - 0s 224us/sample - loss: 4083029656432.3926 - mae: 202008.7656 - mse: 4083029639168.0000 - val_loss: 782907214.4610 - val_mae: 3025.1282 - val_mse: 782907200.0000\n",
      "Epoch 133/500\n",
      "353/353 [==============================] - 0s 327us/sample - loss: 3935866370137.9268 - mae: 199498.4219 - mse: 3935866454016.0000 - val_loss: 756328568.7533 - val_mae: 2972.8789 - val_mse: 756328576.0000\n",
      "Epoch 134/500\n",
      "353/353 [==============================] - 0s 262us/sample - loss: 3770463739825.1929 - mae: 195540.3281 - mse: 3770463813632.0000 - val_loss: 732330278.3008 - val_mae: 2924.9421 - val_mse: 732330304.0000\n",
      "Epoch 135/500\n",
      "353/353 [==============================] - 0s 304us/sample - loss: 3624612318387.7109 - mae: 191235.7656 - mse: 3624612397056.0000 - val_loss: 712690704.1743 - val_mae: 2885.1453 - val_mse: 712690688.0000\n",
      "Epoch 136/500\n",
      "353/353 [==============================] - 0s 288us/sample - loss: 3499099937447.8828 - mae: 188698.3906 - mse: 3499099947008.0000 - val_loss: 690271774.8514 - val_mae: 2839.0237 - val_mse: 690271744.0000\n",
      "Epoch 137/500\n",
      "353/353 [==============================] - 0s 340us/sample - loss: 3360542151760.3799 - mae: 184945.2969 - mse: 3360542687232.0000 - val_loss: 670439595.3935 - val_mae: 2797.5930 - val_mse: 670439616.0000\n",
      "Epoch 138/500\n",
      "353/353 [==============================] - 0s 222us/sample - loss: 3242658790501.5298 - mae: 181545.2188 - mse: 3242659151872.0000 - val_loss: 651242896.5377 - val_mae: 2756.8823 - val_mse: 651242880.0000\n",
      "Epoch 139/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 3120457095528.6958 - mae: 178583.3125 - mse: 3120457056256.0000 - val_loss: 630835987.2294 - val_mae: 2712.9700 - val_mse: 630836032.0000\n",
      "Epoch 140/500\n",
      "353/353 [==============================] - 0s 381us/sample - loss: 2990383673685.5752 - mae: 175800.0938 - mse: 2990383824896.0000 - val_loss: 609124612.3706 - val_mae: 2665.4668 - val_mse: 609124608.0000\n",
      "Epoch 141/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 2867758393900.2378 - mae: 171615.2031 - mse: 2867758628864.0000 - val_loss: 590994906.7215 - val_mae: 2625.1736 - val_mse: 590994880.0000\n",
      "Epoch 142/500\n",
      "353/353 [==============================] - 0s 299us/sample - loss: 2765917070780.8960 - mae: 168804.5156 - mse: 2765916995584.0000 - val_loss: 573500729.9660 - val_mae: 2585.7400 - val_mse: 573500672.0000\n",
      "Epoch 143/500\n",
      "353/353 [==============================] - 0s 272us/sample - loss: 2657271908729.1104 - mae: 166073.6562 - mse: 2657271939072.0000 - val_loss: 554863533.6284 - val_mae: 2543.0278 - val_mse: 554863552.0000\n",
      "Epoch 144/500\n",
      "353/353 [==============================] - 0s 357us/sample - loss: 2547492263323.0298 - mae: 162829.7656 - mse: 2547492323328.0000 - val_loss: 535939939.8053 - val_mae: 2498.9478 - val_mse: 535939968.0000\n",
      "Epoch 145/500\n",
      "353/353 [==============================] - 0s 307us/sample - loss: 2439352868247.4673 - mae: 159851.1406 - mse: 2439352942592.0000 - val_loss: 518274789.3419 - val_mae: 2457.0803 - val_mse: 518274752.0000\n",
      "Epoch 146/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 2343819541306.7388 - mae: 156721.3438 - mse: 2343819542528.0000 - val_loss: 502135659.7664 - val_mae: 2418.2422 - val_mse: 502135648.0000\n",
      "Epoch 147/500\n",
      "353/353 [==============================] - 0s 346us/sample - loss: 2248151065790.3760 - mae: 153957.1719 - mse: 2248151138304.0000 - val_loss: 485220956.3265 - val_mae: 2376.8464 - val_mse: 485220960.0000\n",
      "Epoch 148/500\n",
      "353/353 [==============================] - 0s 304us/sample - loss: 2155327626862.8669 - mae: 150708.7344 - mse: 2155327782912.0000 - val_loss: 469436062.8660 - val_mae: 2337.5547 - val_mse: 469436064.0000\n",
      "Epoch 149/500\n",
      "353/353 [==============================] - 0s 230us/sample - loss: 2072220933596.2832 - mae: 147666.1406 - mse: 2072220925952.0000 - val_loss: 455295696.6308 - val_mae: 2301.7827 - val_mse: 455295712.0000\n",
      "Epoch 150/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 1991076335852.4409 - mae: 145216.3438 - mse: 1991076478976.0000 - val_loss: 440286837.4618 - val_mae: 2263.2065 - val_mse: 440286848.0000\n",
      "Epoch 151/500\n",
      "353/353 [==============================] - 0s 278us/sample - loss: 1908723754246.7083 - mae: 142719.9688 - mse: 1908723810304.0000 - val_loss: 424666199.7806 - val_mae: 2222.3572 - val_mse: 424666208.0000\n",
      "Epoch 152/500\n",
      "353/353 [==============================] - 0s 297us/sample - loss: 1825254761658.7561 - mae: 139603.8438 - mse: 1825254801408.0000 - val_loss: 411059145.4426 - val_mae: 2186.1721 - val_mse: 411059136.0000\n",
      "Epoch 153/500\n",
      "353/353 [==============================] - 0s 276us/sample - loss: 1749741051605.7217 - mae: 136918.1094 - mse: 1749740945408.0000 - val_loss: 397119761.8640 - val_mae: 2148.4724 - val_mse: 397119776.0000\n",
      "Epoch 154/500\n",
      "353/353 [==============================] - 0s 264us/sample - loss: 1674649085551.5466 - mae: 134353.5469 - mse: 1674649272320.0000 - val_loss: 383445813.8928 - val_mae: 2110.8328 - val_mse: 383445824.0000\n",
      "Epoch 155/500\n",
      "353/353 [==============================] - 0s 285us/sample - loss: 1602849990327.4788 - mae: 131558.5469 - mse: 1602850127872.0000 - val_loss: 370420164.4325 - val_mae: 2074.3564 - val_mse: 370420160.0000\n",
      "Epoch 156/500\n",
      "353/353 [==============================] - 0s 261us/sample - loss: 1535954464142.0144 - mae: 128549.7031 - mse: 1535954518016.0000 - val_loss: 358890850.0301 - val_mae: 2041.5645 - val_mse: 358890848.0000\n",
      "Epoch 157/500\n",
      "353/353 [==============================] - 0s 294us/sample - loss: 1478750759900.1021 - mae: 126357.9922 - mse: 1478750765056.0000 - val_loss: 347736804.9942 - val_mae: 2009.3669 - val_mse: 347736800.0000\n",
      "Epoch 158/500\n",
      "353/353 [==============================] - 0s 299us/sample - loss: 1419169901383.2522 - mae: 123848.6797 - mse: 1419169890304.0000 - val_loss: 335805414.8271 - val_mae: 1974.3417 - val_mse: 335805440.0000\n",
      "Epoch 159/500\n",
      "353/353 [==============================] - 0s 298us/sample - loss: 1359477359321.0652 - mae: 121673.5859 - mse: 1359477473280.0000 - val_loss: 324207711.9882 - val_mae: 1939.7020 - val_mse: 324207712.0000\n",
      "Epoch 160/500\n",
      "353/353 [==============================] - 0s 399us/sample - loss: 1298694288790.5728 - mae: 119336.5703 - mse: 1298694275072.0000 - val_loss: 312128129.3889 - val_mae: 1902.9580 - val_mse: 312128128.0000\n",
      "Epoch 161/500\n",
      "353/353 [==============================] - 0s 567us/sample - loss: 1238966489585.8479 - mae: 116530.5078 - mse: 1238966468608.0000 - val_loss: 301363183.6215 - val_mae: 1869.6166 - val_mse: 301363168.0000\n",
      "Epoch 162/500\n",
      "353/353 [==============================] - 0s 408us/sample - loss: 1186336271645.4014 - mae: 114577.9062 - mse: 1186336210944.0000 - val_loss: 290847335.3620 - val_mae: 1836.4642 - val_mse: 290847328.0000\n",
      "Epoch 163/500\n",
      "353/353 [==============================] - 0s 318us/sample - loss: 1131794780827.5566 - mae: 112093.4531 - mse: 1131794661376.0000 - val_loss: 280495581.2517 - val_mae: 1803.2521 - val_mse: 280495584.0000\n",
      "Epoch 164/500\n",
      "353/353 [==============================] - 0s 399us/sample - loss: 1079575362349.2749 - mae: 109894.3672 - mse: 1079575379968.0000 - val_loss: 270042853.2113 - val_mae: 1769.0704 - val_mse: 270042848.0000\n",
      "Epoch 165/500\n",
      "353/353 [==============================] - 0s 282us/sample - loss: 1028306469750.5723 - mae: 107350.1875 - mse: 1028306436096.0000 - val_loss: 260538697.8050 - val_mae: 1737.4143 - val_mse: 260538720.0000\n",
      "Epoch 166/500\n",
      "353/353 [==============================] - 0s 261us/sample - loss: 984487814175.3569 - mae: 105055.1016 - mse: 984487821312.0000 - val_loss: 251775438.2050 - val_mae: 1707.7319 - val_mse: 251775440.0000\n",
      "Epoch 167/500\n",
      "353/353 [==============================] - 0s 296us/sample - loss: 940821388973.6644 - mae: 103027.2656 - mse: 940821381120.0000 - val_loss: 243175673.7049 - val_mae: 1678.0808 - val_mse: 243175648.0000\n",
      "Epoch 168/500\n",
      "353/353 [==============================] - 0s 306us/sample - loss: 899710604437.2546 - mae: 100547.4766 - mse: 899710582784.0000 - val_loss: 234652629.4430 - val_mae: 1648.1835 - val_mse: 234652608.0000\n",
      "Epoch 169/500\n",
      "353/353 [==============================] - 0s 343us/sample - loss: 859590908989.2747 - mae: 98625.1094 - mse: 859590885376.0000 - val_loss: 225738277.9241 - val_mae: 1616.3281 - val_mse: 225738272.0000\n",
      "Epoch 170/500\n",
      "353/353 [==============================] - 0s 409us/sample - loss: 819595146860.7820 - mae: 96313.8672 - mse: 819595116544.0000 - val_loss: 217408711.9856 - val_mae: 1585.9340 - val_mse: 217408704.0000\n",
      "Epoch 171/500\n",
      "353/353 [==============================] - 0s 418us/sample - loss: 782296577130.2504 - mae: 94447.9688 - mse: 782296481792.0000 - val_loss: 209603046.1801 - val_mae: 1556.9943 - val_mse: 209603040.0000\n",
      "Epoch 172/500\n",
      "353/353 [==============================] - 0s 290us/sample - loss: 745096802894.9406 - mae: 92305.2891 - mse: 745096871936.0000 - val_loss: 201605811.0737 - val_mae: 1526.7720 - val_mse: 201605808.0000\n",
      "Epoch 173/500\n",
      "353/353 [==============================] - 0s 362us/sample - loss: 709887034576.3344 - mae: 90387.8203 - mse: 709887066112.0000 - val_loss: 193776949.8616 - val_mae: 1496.6023 - val_mse: 193776944.0000\n",
      "Epoch 174/500\n",
      "353/353 [==============================] - 0s 241us/sample - loss: 676938344907.8413 - mae: 88409.1406 - mse: 676938383360.0000 - val_loss: 186264413.6103 - val_mae: 1467.0636 - val_mse: 186264416.0000\n",
      "Epoch 175/500\n",
      "353/353 [==============================] - 0s 286us/sample - loss: 642865500267.3314 - mae: 86558.2969 - mse: 642865496064.0000 - val_loss: 178879647.6515 - val_mae: 1437.4341 - val_mse: 178879632.0000\n",
      "Epoch 176/500\n",
      "353/353 [==============================] - 0s 289us/sample - loss: 611691928090.3630 - mae: 84495.8906 - mse: 611691855872.0000 - val_loss: 172139808.4888 - val_mae: 1409.8715 - val_mse: 172139808.0000\n",
      "Epoch 177/500\n",
      "353/353 [==============================] - 0s 299us/sample - loss: 584486446191.0255 - mae: 82777.8047 - mse: 584486486016.0000 - val_loss: 165538819.9848 - val_mae: 1382.3644 - val_mse: 165538816.0000\n",
      "Epoch 178/500\n",
      "353/353 [==============================] - 0s 359us/sample - loss: 556875608100.5593 - mae: 80692.5469 - mse: 556875513856.0000 - val_loss: 159559608.6483 - val_mae: 1356.9771 - val_mse: 159559616.0000\n",
      "Epoch 179/500\n",
      "353/353 [==============================] - 0s 340us/sample - loss: 533841691988.8046 - mae: 79233.7891 - mse: 533841641472.0000 - val_loss: 153393545.7319 - val_mae: 1330.2972 - val_mse: 153393536.0000\n",
      "Epoch 180/500\n",
      "353/353 [==============================] - 0s 317us/sample - loss: 506472145222.7833 - mae: 77624.2344 - mse: 506472169472.0000 - val_loss: 146544552.9773 - val_mae: 1300.0057 - val_mse: 146544560.0000\n",
      "Epoch 181/500\n",
      "353/353 [==============================] - 0s 345us/sample - loss: 480624346227.1274 - mae: 75588.6953 - mse: 480624312320.0000 - val_loss: 140564570.9152 - val_mae: 1272.9779 - val_mse: 140564576.0000\n",
      "Epoch 182/500\n",
      "353/353 [==============================] - 0s 292us/sample - loss: 459431858378.2294 - mae: 73816.3984 - mse: 459431837696.0000 - val_loss: 135306465.1926 - val_mae: 1248.7513 - val_mse: 135306464.0000\n",
      "Epoch 183/500\n",
      "353/353 [==============================] - 0s 332us/sample - loss: 440077288869.7625 - mae: 72409.4609 - mse: 440077320192.0000 - val_loss: 129649389.4854 - val_mae: 1222.1434 - val_mse: 129649400.0000\n",
      "Epoch 184/500\n",
      "353/353 [==============================] - 0s 400us/sample - loss: 420466856446.4278 - mae: 70698.0000 - mse: 420466917376.0000 - val_loss: 124968096.6133 - val_mae: 1199.6843 - val_mse: 124968096.0000\n",
      "Epoch 185/500\n",
      "353/353 [==============================] - 0s 363us/sample - loss: 402062600394.7882 - mae: 69318.7188 - mse: 402062573568.0000 - val_loss: 119591782.0308 - val_mae: 1173.3781 - val_mse: 119591776.0000\n",
      "Epoch 186/500\n",
      "353/353 [==============================] - 0s 363us/sample - loss: 383471932796.5447 - mae: 67683.1328 - mse: 383471910912.0000 - val_loss: 114567022.8520 - val_mae: 1148.2610 - val_mse: 114567016.0000\n",
      "Epoch 187/500\n",
      "353/353 [==============================] - 0s 344us/sample - loss: 366685584349.8571 - mae: 66268.6875 - mse: 366685585408.0000 - val_loss: 110047430.9847 - val_mae: 1125.2032 - val_mse: 110047424.0000\n",
      "Epoch 188/500\n",
      "353/353 [==============================] - 0s 347us/sample - loss: 350185181687.5527 - mae: 65005.4688 - mse: 350185160704.0000 - val_loss: 105013950.8387 - val_mae: 1098.9598 - val_mse: 105013952.0000\n",
      "Epoch 189/500\n",
      "353/353 [==============================] - 0s 296us/sample - loss: 333525728370.8494 - mae: 63475.8594 - mse: 333525745664.0000 - val_loss: 100869305.2856 - val_mae: 1076.8928 - val_mse: 100869304.0000\n",
      "Epoch 190/500\n",
      "353/353 [==============================] - 0s 229us/sample - loss: 318316967830.5936 - mae: 61956.5898 - mse: 318317002752.0000 - val_loss: 96807742.1703 - val_mae: 1054.8331 - val_mse: 96807744.0000\n",
      "Epoch 191/500\n",
      "353/353 [==============================] - 0s 301us/sample - loss: 304740864236.0715 - mae: 60580.9180 - mse: 304740859904.0000 - val_loss: 92500861.6859 - val_mae: 1030.9308 - val_mse: 92500856.0000\n",
      "Epoch 192/500\n",
      "353/353 [==============================] - 0s 202us/sample - loss: 290373741035.8630 - mae: 59180.1484 - mse: 290373795840.0000 - val_loss: 88315181.7418 - val_mae: 1007.1557 - val_mse: 88315176.0000\n",
      "Epoch 193/500\n",
      "353/353 [==============================] - 0s 255us/sample - loss: 275555968524.3378 - mae: 57934.0977 - mse: 275555975168.0000 - val_loss: 83925431.8632 - val_mae: 981.6254 - val_mse: 83925432.0000\n",
      "Epoch 194/500\n",
      "353/353 [==============================] - 0s 356us/sample - loss: 261330278092.5099 - mae: 56400.3242 - mse: 261330288640.0000 - val_loss: 80197740.0976 - val_mae: 959.4226 - val_mse: 80197744.0000\n",
      "Epoch 195/500\n",
      "353/353 [==============================] - 0s 253us/sample - loss: 249612018106.5818 - mae: 55072.6406 - mse: 249612009472.0000 - val_loss: 76683944.2974 - val_mae: 938.0342 - val_mse: 76683944.0000\n",
      "Epoch 196/500\n",
      "353/353 [==============================] - 0s 345us/sample - loss: 238346570728.2153 - mae: 53699.7891 - mse: 238346584064.0000 - val_loss: 73374592.2687 - val_mae: 917.4301 - val_mse: 73374592.0000\n",
      "Epoch 197/500\n",
      "353/353 [==============================] - 0s 313us/sample - loss: 227244365702.0213 - mae: 52714.9922 - mse: 227244376064.0000 - val_loss: 70050651.2166 - val_mae: 896.2712 - val_mse: 70050648.0000\n",
      "Epoch 198/500\n",
      "353/353 [==============================] - 0s 249us/sample - loss: 215662103488.7535 - mae: 51392.7266 - mse: 215662100480.0000 - val_loss: 66952013.7521 - val_mae: 876.1346 - val_mse: 66952012.0000\n",
      "Epoch 199/500\n",
      "353/353 [==============================] - 0s 285us/sample - loss: 205582311487.7563 - mae: 50057.8477 - mse: 205582303232.0000 - val_loss: 64224600.3237 - val_mae: 858.0243 - val_mse: 64224600.0000\n",
      "Epoch 200/500\n",
      "353/353 [==============================] - 0s 309us/sample - loss: 196647087064.5006 - mae: 49064.9336 - mse: 196647092224.0000 - val_loss: 61288509.0978 - val_mae: 838.0980 - val_mse: 61288512.0000\n",
      "Epoch 201/500\n",
      "353/353 [==============================] - 0s 226us/sample - loss: 186926397206.4136 - mae: 47807.4336 - mse: 186926399488.0000 - val_loss: 58423499.7899 - val_mae: 818.1881 - val_mse: 58423496.0000\n",
      "Epoch 202/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 177777579620.7945 - mae: 46727.4805 - mse: 177777573888.0000 - val_loss: 55638696.4336 - val_mae: 798.3676 - val_mse: 55638696.0000\n",
      "Epoch 203/500\n",
      "353/353 [==============================] - 0s 236us/sample - loss: 169017362262.9428 - mae: 45418.1836 - mse: 169017344000.0000 - val_loss: 53233199.6861 - val_mae: 780.8470 - val_mse: 53233200.0000\n",
      "Epoch 204/500\n",
      "353/353 [==============================] - 0s 236us/sample - loss: 161275871031.0475 - mae: 44440.4219 - mse: 161275904000.0000 - val_loss: 50632089.7410 - val_mae: 761.5012 - val_mse: 50632088.0000\n",
      "Epoch 205/500\n",
      "353/353 [==============================] - 0s 298us/sample - loss: 153176660583.6202 - mae: 43264.6914 - mse: 153176653824.0000 - val_loss: 48208425.6077 - val_mae: 743.0865 - val_mse: 48208424.0000\n",
      "Epoch 206/500\n",
      "353/353 [==============================] - 0s 256us/sample - loss: 144787688735.7980 - mae: 42354.1953 - mse: 144787701760.0000 - val_loss: 45637448.8738 - val_mae: 722.9949 - val_mse: 45637448.0000\n",
      "Epoch 207/500\n",
      "353/353 [==============================] - 0s 256us/sample - loss: 136392813731.5476 - mae: 41168.6367 - mse: 136392810496.0000 - val_loss: 43269509.4029 - val_mae: 703.9409 - val_mse: 43269508.0000\n",
      "Epoch 208/500\n",
      "353/353 [==============================] - 0s 303us/sample - loss: 129141284752.7600 - mae: 39989.6133 - mse: 129141293056.0000 - val_loss: 41230171.2300 - val_mae: 687.1149 - val_mse: 41230172.0000\n",
      "Epoch 209/500\n",
      "353/353 [==============================] - 0s 217us/sample - loss: 123348057002.5326 - mae: 39031.4805 - mse: 123348041728.0000 - val_loss: 39544346.9749 - val_mae: 672.8953 - val_mse: 39544344.0000\n",
      "Epoch 210/500\n",
      "353/353 [==============================] - 0s 347us/sample - loss: 116630533686.9156 - mae: 38209.0625 - mse: 116630536192.0000 - val_loss: 37196295.1601 - val_mae: 652.5728 - val_mse: 37196292.0000\n",
      "Epoch 211/500\n",
      "353/353 [==============================] - 0s 198us/sample - loss: 109958821066.9575 - mae: 37037.2070 - mse: 109958823936.0000 - val_loss: 35287922.9626 - val_mae: 635.5776 - val_mse: 35287924.0000\n",
      "Epoch 212/500\n",
      "353/353 [==============================] - 0s 260us/sample - loss: 104378660070.9429 - mae: 36071.7383 - mse: 104378654720.0000 - val_loss: 33577571.6054 - val_mae: 619.9567 - val_mse: 33577572.0000\n",
      "Epoch 213/500\n",
      "353/353 [==============================] - 0s 291us/sample - loss: 99196077776.8612 - mae: 35147.9805 - mse: 99196076032.0000 - val_loss: 32191492.4338 - val_mae: 607.0005 - val_mse: 32191494.0000\n",
      "Epoch 214/500\n",
      "353/353 [==============================] - 0s 252us/sample - loss: 94691180889.6232 - mae: 34332.3359 - mse: 94691180544.0000 - val_loss: 30574785.5586 - val_mae: 591.5345 - val_mse: 30574784.0000\n",
      "Epoch 215/500\n",
      "353/353 [==============================] - 0s 252us/sample - loss: 89746223804.3168 - mae: 33580.1641 - mse: 89746227200.0000 - val_loss: 29020364.4852 - val_mae: 576.2730 - val_mse: 29020364.0000\n",
      "Epoch 216/500\n",
      "353/353 [==============================] - 0s 231us/sample - loss: 84760905981.0992 - mae: 32608.2832 - mse: 84760903680.0000 - val_loss: 27434909.7462 - val_mae: 560.2734 - val_mse: 27434910.0000\n",
      "Epoch 217/500\n",
      "353/353 [==============================] - 0s 276us/sample - loss: 80167032764.5552 - mae: 31599.5098 - mse: 80167026688.0000 - val_loss: 26012375.0675 - val_mae: 545.5270 - val_mse: 26012376.0000\n",
      "Epoch 218/500\n",
      "353/353 [==============================] - 0s 321us/sample - loss: 75877621002.7346 - mae: 30869.1191 - mse: 75877613568.0000 - val_loss: 24583155.6932 - val_mae: 530.3068 - val_mse: 24583156.0000\n",
      "Epoch 219/500\n",
      "353/353 [==============================] - 0s 282us/sample - loss: 71372765435.4674 - mae: 29994.2148 - mse: 71372759040.0000 - val_loss: 23298291.7929 - val_mae: 516.2354 - val_mse: 23298292.0000\n",
      "Epoch 220/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 67228912104.6346 - mae: 29177.6406 - mse: 67228913664.0000 - val_loss: 21931765.1818 - val_mae: 500.8376 - val_mse: 21931764.0000\n",
      "Epoch 221/500\n",
      "353/353 [==============================] - 0s 230us/sample - loss: 63340886136.0680 - mae: 28346.8242 - mse: 63340888064.0000 - val_loss: 20678349.1198 - val_mae: 486.2856 - val_mse: 20678350.0000\n",
      "Epoch 222/500\n",
      "353/353 [==============================] - 0s 303us/sample - loss: 59719273865.9479 - mae: 27446.4043 - mse: 59719274496.0000 - val_loss: 19590126.7848 - val_mae: 473.2911 - val_mse: 19590126.0000\n",
      "Epoch 223/500\n",
      "353/353 [==============================] - 0s 339us/sample - loss: 56692244521.0397 - mae: 26707.1250 - mse: 56692256768.0000 - val_loss: 18578818.2399 - val_mae: 460.8880 - val_mse: 18578818.0000\n",
      "Epoch 224/500\n",
      "353/353 [==============================] - 0s 342us/sample - loss: 53662176789.2225 - mae: 25942.1836 - mse: 53662175232.0000 - val_loss: 17538488.1621 - val_mae: 447.7713 - val_mse: 17538488.0000\n",
      "Epoch 225/500\n",
      "353/353 [==============================] - 0s 341us/sample - loss: 50660438392.8839 - mae: 25233.9141 - mse: 50660442112.0000 - val_loss: 16598698.6962 - val_mae: 435.5823 - val_mse: 16598699.0000\n",
      "Epoch 226/500\n",
      "353/353 [==============================] - 0s 260us/sample - loss: 47592571602.7019 - mae: 24623.6797 - mse: 47592570880.0000 - val_loss: 15652907.6271 - val_mae: 422.9648 - val_mse: 15652907.0000\n",
      "Epoch 227/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 44663299784.5212 - mae: 23774.5352 - mse: 44663300096.0000 - val_loss: 14741951.3185 - val_mae: 410.4442 - val_mse: 14741951.0000\n",
      "Epoch 228/500\n",
      "353/353 [==============================] - 0s 216us/sample - loss: 41924321362.6767 - mae: 23121.5293 - mse: 41924317184.0000 - val_loss: 13828751.4672 - val_mae: 397.5025 - val_mse: 13828752.0000\n",
      "Epoch 229/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 39396772608.9848 - mae: 22435.8359 - mse: 39396773888.0000 - val_loss: 12980040.7530 - val_mae: 385.0863 - val_mse: 12980041.0000\n",
      "Epoch 230/500\n",
      "353/353 [==============================] - 0s 242us/sample - loss: 36963551661.6471 - mae: 21736.3535 - mse: 36963549184.0000 - val_loss: 12188966.1852 - val_mae: 373.1436 - val_mse: 12188967.0000\n",
      "Epoch 231/500\n",
      "353/353 [==============================] - 0s 237us/sample - loss: 34706535824.1360 - mae: 21092.7188 - mse: 34706534400.0000 - val_loss: 11445478.9461 - val_mae: 361.5603 - val_mse: 11445479.0000\n",
      "Epoch 232/500\n",
      "353/353 [==============================] - 0s 294us/sample - loss: 32716060976.5666 - mae: 20391.1270 - mse: 32716058624.0000 - val_loss: 10813707.1747 - val_mae: 351.4193 - val_mse: 10813708.0000\n",
      "Epoch 233/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 30878687411.0425 - mae: 19776.1133 - mse: 30878689280.0000 - val_loss: 10198146.8369 - val_mae: 341.2486 - val_mse: 10198147.0000\n",
      "Epoch 234/500\n",
      "353/353 [==============================] - 0s 215us/sample - loss: 29007658199.6148 - mae: 19253.6484 - mse: 29007654912.0000 - val_loss: 9556483.8119 - val_mae: 330.3146 - val_mse: 9556484.0000\n",
      "Epoch 235/500\n",
      "353/353 [==============================] - 0s 307us/sample - loss: 27077024378.7876 - mae: 18634.0391 - mse: 27077023744.0000 - val_loss: 8940217.3397 - val_mae: 319.4623 - val_mse: 8940218.0000\n",
      "Epoch 236/500\n",
      "353/353 [==============================] - 0s 380us/sample - loss: 25433314980.3112 - mae: 18003.0801 - mse: 25433311232.0000 - val_loss: 8429874.6713 - val_mae: 310.1895 - val_mse: 8429874.0000\n",
      "Epoch 237/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 23872646255.8649 - mae: 17481.7695 - mse: 23872645120.0000 - val_loss: 7891758.8174 - val_mae: 300.1007 - val_mse: 7891758.5000\n",
      "Epoch 238/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 22205984497.8584 - mae: 16934.1855 - mse: 22205982720.0000 - val_loss: 7344629.7523 - val_mae: 289.4845 - val_mse: 7344630.0000\n",
      "Epoch 239/500\n",
      "353/353 [==============================] - 0s 330us/sample - loss: 20659411104.5895 - mae: 16290.7539 - mse: 20659412992.0000 - val_loss: 6881724.1287 - val_mae: 280.1893 - val_mse: 6881724.5000\n",
      "Epoch 240/500\n",
      "353/353 [==============================] - 0s 474us/sample - loss: 19491633033.1200 - mae: 15818.6924 - mse: 19491635200.0000 - val_loss: 6488769.9322 - val_mae: 272.0526 - val_mse: 6488770.0000\n",
      "Epoch 241/500\n",
      "353/353 [==============================] - 0s 385us/sample - loss: 18265693706.4680 - mae: 15297.0977 - mse: 18265692160.0000 - val_loss: 6105159.0413 - val_mae: 263.8678 - val_mse: 6105159.0000\n",
      "Epoch 242/500\n",
      "353/353 [==============================] - 0s 340us/sample - loss: 16963831868.8931 - mae: 14889.4307 - mse: 16963831808.0000 - val_loss: 5646771.9401 - val_mae: 253.7426 - val_mse: 5646772.0000\n",
      "Epoch 243/500\n",
      "353/353 [==============================] - 0s 311us/sample - loss: 15741787799.6601 - mae: 14219.1387 - mse: 15741789184.0000 - val_loss: 5311967.9760 - val_mae: 246.0841 - val_mse: 5311968.0000\n",
      "Epoch 244/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 14831620323.7734 - mae: 13805.1572 - mse: 14831620096.0000 - val_loss: 4974610.4917 - val_mae: 238.1198 - val_mse: 4974610.5000\n",
      "Epoch 245/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 13688178592.6307 - mae: 13397.1318 - mse: 13688177664.0000 - val_loss: 4547235.8017 - val_mae: 227.6558 - val_mse: 4547236.0000\n",
      "Epoch 246/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 12588584930.5142 - mae: 12818.3750 - mse: 12588587008.0000 - val_loss: 4222145.1448 - val_mae: 219.3775 - val_mse: 4222145.0000\n",
      "Epoch 247/500\n",
      "353/353 [==============================] - 0s 302us/sample - loss: 11714642869.9444 - mae: 12283.1328 - mse: 11714641920.0000 - val_loss: 3930354.6825 - val_mae: 211.6711 - val_mse: 3930354.7500\n",
      "Epoch 248/500\n",
      "353/353 [==============================] - 0s 319us/sample - loss: 10905646050.6807 - mae: 11846.3066 - mse: 10905646080.0000 - val_loss: 3630618.8752 - val_mae: 203.4512 - val_mse: 3630619.0000\n",
      "Epoch 249/500\n",
      "353/353 [==============================] - 0s 300us/sample - loss: 9980966730.2364 - mae: 11470.4033 - mse: 9980966912.0000 - val_loss: 3310238.3777 - val_mae: 194.2801 - val_mse: 3310238.2500\n",
      "Epoch 250/500\n",
      "353/353 [==============================] - 0s 306us/sample - loss: 9212842349.1021 - mae: 10952.1807 - mse: 9212840960.0000 - val_loss: 3079275.3647 - val_mae: 187.3898 - val_mse: 3079275.5000\n",
      "Epoch 251/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 8495722464.5395 - mae: 10565.0430 - mse: 8495723008.0000 - val_loss: 2839838.6422 - val_mae: 179.9678 - val_mse: 2839838.5000\n",
      "Epoch 252/500\n",
      "353/353 [==============================] - 0s 274us/sample - loss: 7860269087.1850 - mae: 10178.7646 - mse: 7860269056.0000 - val_loss: 2618663.7061 - val_mae: 172.8278 - val_mse: 2618663.7500\n",
      "Epoch 253/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 7208343320.4783 - mae: 9731.7451 - mse: 7208343552.0000 - val_loss: 2408200.1653 - val_mae: 165.7484 - val_mse: 2408200.0000\n",
      "Epoch 254/500\n",
      "353/353 [==============================] - 0s 308us/sample - loss: 6652125878.5851 - mae: 9312.4189 - mse: 6652126208.0000 - val_loss: 2219561.5561 - val_mae: 159.1391 - val_mse: 2219561.5000\n",
      "Epoch 255/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 6143602209.1533 - mae: 8995.9658 - mse: 6143602176.0000 - val_loss: 2044725.3987 - val_mae: 152.7565 - val_mse: 2044725.3750\n",
      "Epoch 256/500\n",
      "353/353 [==============================] - 0s 377us/sample - loss: 5651497704.6677 - mae: 8602.3643 - mse: 5651497984.0000 - val_loss: 1866931.7608 - val_mae: 145.9761 - val_mse: 1866931.7500\n",
      "Epoch 257/500\n",
      "353/353 [==============================] - 0s 261us/sample - loss: 5222423892.7819 - mae: 8284.8369 - mse: 5222424576.0000 - val_loss: 1727980.7780 - val_mae: 140.4473 - val_mse: 1727980.7500\n",
      "Epoch 258/500\n",
      "353/353 [==============================] - 0s 207us/sample - loss: 4788736777.1196 - mae: 7927.6919 - mse: 4788736512.0000 - val_loss: 1584839.4142 - val_mae: 134.5131 - val_mse: 1584839.3750\n",
      "Epoch 259/500\n",
      "353/353 [==============================] - 0s 351us/sample - loss: 4341495596.9120 - mae: 7611.2363 - mse: 4341495808.0000 - val_loss: 1422157.7201 - val_mae: 127.4282 - val_mse: 1422157.7500\n",
      "Epoch 260/500\n",
      "353/353 [==============================] - 0s 326us/sample - loss: 3922132146.9235 - mae: 7219.7407 - mse: 3922131968.0000 - val_loss: 1292355.9748 - val_mae: 121.4766 - val_mse: 1292356.0000\n",
      "Epoch 261/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 3567542502.8829 - mae: 6858.3926 - mse: 3567542272.0000 - val_loss: 1172054.5614 - val_mae: 115.6967 - val_mse: 1172054.5000\n",
      "Epoch 262/500\n",
      "353/353 [==============================] - 0s 203us/sample - loss: 3220306063.9553 - mae: 6562.1133 - mse: 3220306176.0000 - val_loss: 1039815.0805 - val_mae: 108.9988 - val_mse: 1039815.1250\n",
      "Epoch 263/500\n",
      "353/353 [==============================] - 0s 234us/sample - loss: 2873309473.1246 - mae: 6217.7422 - mse: 2873309440.0000 - val_loss: 925277.2871 - val_mae: 102.8445 - val_mse: 925277.3125\n",
      "Epoch 264/500\n",
      "353/353 [==============================] - 0s 282us/sample - loss: 2590542117.5454 - mae: 5887.8320 - mse: 2590541824.0000 - val_loss: 834805.9457 - val_mae: 97.7080 - val_mse: 834805.9375\n",
      "Epoch 265/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 2344310867.8881 - mae: 5557.4849 - mse: 2344310784.0000 - val_loss: 754015.1118 - val_mae: 92.8805 - val_mse: 754015.1250\n",
      "Epoch 266/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 2100186769.2163 - mae: 5313.1294 - mse: 2100186752.0000 - val_loss: 661949.9431 - val_mae: 87.0524 - val_mse: 661949.9375\n",
      "Epoch 267/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 1853693765.0247 - mae: 5006.5161 - mse: 1853693696.0000 - val_loss: 581070.4962 - val_mae: 81.6006 - val_mse: 581070.5000\n",
      "Epoch 268/500\n",
      "353/353 [==============================] - 0s 236us/sample - loss: 1644663882.3829 - mae: 4684.3604 - mse: 1644663936.0000 - val_loss: 510207.1061 - val_mae: 76.5078 - val_mse: 510207.0938\n",
      "Epoch 269/500\n",
      "353/353 [==============================] - 0s 292us/sample - loss: 1451637689.0856 - mae: 4419.0552 - mse: 1451637760.0000 - val_loss: 445557.9730 - val_mae: 71.5427 - val_mse: 445557.9688\n",
      "Epoch 270/500\n",
      "353/353 [==============================] - 0s 276us/sample - loss: 1278013534.2890 - mae: 4145.2959 - mse: 1278013696.0000 - val_loss: 385574.1974 - val_mae: 66.6016 - val_mse: 385574.1875\n",
      "Epoch 271/500\n",
      "353/353 [==============================] - 0s 300us/sample - loss: 1119639386.2657 - mae: 3836.2476 - mse: 1119639296.0000 - val_loss: 335396.2499 - val_mae: 62.1805 - val_mse: 335396.2500\n",
      "Epoch 272/500\n",
      "353/353 [==============================] - 0s 311us/sample - loss: 973841631.0516 - mae: 3614.0989 - mse: 973841536.0000 - val_loss: 283496.6043 - val_mae: 57.2495 - val_mse: 283496.5938\n",
      "Epoch 273/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 835955623.1826 - mae: 3340.4026 - mse: 835955712.0000 - val_loss: 239900.7403 - val_mae: 52.7452 - val_mse: 239900.7344\n",
      "Epoch 274/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 713410991.4690 - mae: 3101.9553 - mse: 713411008.0000 - val_loss: 200110.8828 - val_mae: 48.2604 - val_mse: 200110.8750\n",
      "Epoch 275/500\n",
      "353/353 [==============================] - 0s 266us/sample - loss: 603184634.7932 - mae: 2839.6560 - mse: 603184640.0000 - val_loss: 165441.6934 - val_mae: 43.9743 - val_mse: 165441.6875\n",
      "Epoch 276/500\n",
      "353/353 [==============================] - 0s 254us/sample - loss: 498457978.8725 - mae: 2619.7793 - mse: 498457984.0000 - val_loss: 126989.4773 - val_mae: 38.6661 - val_mse: 126989.4688\n",
      "Epoch 277/500\n",
      "353/353 [==============================] - 0s 285us/sample - loss: 411978008.6125 - mae: 2371.6006 - mse: 411978016.0000 - val_loss: 122065.1017 - val_mae: 37.9289 - val_mse: 122065.1016\n",
      "Epoch 278/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 403862165.3941 - mae: 2338.9041 - mse: 403862112.0000 - val_loss: 114941.2701 - val_mae: 36.8369 - val_mse: 114941.2734\n",
      "Epoch 279/500\n",
      "353/353 [==============================] - 0s 255us/sample - loss: 392535222.5100 - mae: 2290.9875 - mse: 392535264.0000 - val_loss: 107213.9239 - val_mae: 35.6138 - val_mse: 107213.9219\n",
      "Epoch 280/500\n",
      "353/353 [==============================] - 0s 236us/sample - loss: 377316954.2500 - mae: 2241.3450 - mse: 377316928.0000 - val_loss: 95999.1703 - val_mae: 33.7580 - val_mse: 95999.1719\n",
      "Epoch 281/500\n",
      "353/353 [==============================] - 0s 338us/sample - loss: 349177890.7063 - mae: 2128.4294 - mse: 349177888.0000 - val_loss: 84391.6665 - val_mae: 31.7187 - val_mse: 84391.6719\n",
      "Epoch 282/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 316651657.6208 - mae: 2021.6969 - mse: 316651680.0000 - val_loss: 69339.5533 - val_mae: 28.8545 - val_mse: 69339.5547\n",
      "Epoch 283/500\n",
      "353/353 [==============================] - 0s 223us/sample - loss: 270878497.7962 - mae: 1887.8387 - mse: 270878496.0000 - val_loss: 53003.7024 - val_mae: 25.3653 - val_mse: 53003.7031\n",
      "Epoch 284/500\n",
      "353/353 [==============================] - 0s 308us/sample - loss: 217253402.2135 - mae: 1657.2869 - mse: 217253392.0000 - val_loss: 40206.0995 - val_mae: 22.2315 - val_mse: 40206.0977\n",
      "Epoch 285/500\n",
      "353/353 [==============================] - 0s 308us/sample - loss: 171300341.9467 - mae: 1502.7924 - mse: 171300336.0000 - val_loss: 27357.5379 - val_mae: 18.5272 - val_mse: 27357.5371\n",
      "Epoch 286/500\n",
      "353/353 [==============================] - 0s 331us/sample - loss: 129246609.1447 - mae: 1271.5834 - mse: 129246624.0000 - val_loss: 18965.3224 - val_mae: 15.6071 - val_mse: 18965.3223\n",
      "Epoch 287/500\n",
      "353/353 [==============================] - 0s 220us/sample - loss: 98736609.1637 - mae: 1099.6792 - mse: 98736624.0000 - val_loss: 11822.8203 - val_mae: 12.5480 - val_mse: 11822.8203\n",
      "Epoch 288/500\n",
      "353/353 [==============================] - 0s 296us/sample - loss: 71222868.9755 - mae: 921.5252 - mse: 71222872.0000 - val_loss: 6224.8003 - val_mae: 9.4007 - val_mse: 6224.8008\n",
      "Epoch 289/500\n",
      "353/353 [==============================] - 0s 294us/sample - loss: 45655839.1004 - mae: 768.9134 - mse: 45655836.0000 - val_loss: 2231.6105 - val_mae: 6.0599 - val_mse: 2231.6104\n",
      "Epoch 290/500\n",
      "353/353 [==============================] - 0s 300us/sample - loss: 27189679.8990 - mae: 565.2229 - mse: 27189680.0000 - val_loss: 473.5676 - val_mae: 3.3656 - val_mse: 473.5676\n",
      "Epoch 291/500\n",
      "353/353 [==============================] - 0s 222us/sample - loss: 13824525.1995 - mae: 436.0336 - mse: 13824525.0000 - val_loss: 37.1716 - val_mae: 1.6904 - val_mse: 37.1716\n",
      "Epoch 292/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 5822127.0121 - mae: 281.7766 - mse: 5822127.0000 - val_loss: 577.0819 - val_mae: 3.6231 - val_mse: 577.0820\n",
      "Epoch 293/500\n",
      "353/353 [==============================] - 0s 301us/sample - loss: 2015295.8507 - mae: 177.8937 - mse: 2015295.8750 - val_loss: 2035.7158 - val_mae: 5.8717 - val_mse: 2035.7158\n",
      "Epoch 294/500\n",
      "353/353 [==============================] - 0s 318us/sample - loss: 587175.9775 - mae: 104.8466 - mse: 587175.9375 - val_loss: 2472.9751 - val_mae: 6.3609 - val_mse: 2472.9753\n",
      "Epoch 295/500\n",
      "353/353 [==============================] - 0s 212us/sample - loss: 503647.7012 - mae: 103.5525 - mse: 503647.6875 - val_loss: 2622.8517 - val_mae: 6.5168 - val_mse: 2622.8516\n",
      "Epoch 296/500\n",
      "353/353 [==============================] - 0s 246us/sample - loss: 316608.1944 - mae: 89.8043 - mse: 316608.2188 - val_loss: 4836.2433 - val_mae: 8.4684 - val_mse: 4836.2432\n",
      "Epoch 297/500\n",
      "353/353 [==============================] - 0s 302us/sample - loss: 903222.7867 - mae: 129.3278 - mse: 903222.7500 - val_loss: 3338.5968 - val_mae: 7.2123 - val_mse: 3338.5969\n",
      "Epoch 298/500\n",
      "353/353 [==============================] - 0s 406us/sample - loss: 256214.0594 - mae: 93.9003 - mse: 256214.0469 - val_loss: 6049.8091 - val_mae: 9.3415 - val_mse: 6049.8096\n",
      "Epoch 299/500\n",
      "353/353 [==============================] - 0s 268us/sample - loss: 831510.8746 - mae: 134.2456 - mse: 831510.8750 - val_loss: 3299.9283 - val_mae: 7.1709 - val_mse: 3299.9285\n",
      "Epoch 300/500\n",
      "353/353 [==============================] - 0s 273us/sample - loss: 398231.6092 - mae: 100.4308 - mse: 398231.6250 - val_loss: 5443.5415 - val_mae: 8.9108 - val_mse: 5443.5420\n",
      "Epoch 301/500\n",
      "353/353 [==============================] - 0s 232us/sample - loss: 378510.2474 - mae: 98.7516 - mse: 378510.2500 - val_loss: 5092.3989 - val_mae: 8.6517 - val_mse: 5092.3989\n",
      "Epoch 302/500\n",
      "353/353 [==============================] - 0s 195us/sample - loss: 312058.3636 - mae: 100.1331 - mse: 312058.3750 - val_loss: 6455.6790 - val_mae: 9.6075 - val_mse: 6455.6792\n",
      "Epoch 303/500\n",
      "353/353 [==============================] - 0s 209us/sample - loss: 1028427.6026 - mae: 145.3207 - mse: 1028427.5000 - val_loss: 2899.5970 - val_mae: 6.7812 - val_mse: 2899.5972\n",
      "Epoch 304/500\n",
      "353/353 [==============================] - 0s 305us/sample - loss: 632319.7281 - mae: 118.3476 - mse: 632319.7500 - val_loss: 4160.6608 - val_mae: 7.9156 - val_mse: 4160.6606\n",
      "Epoch 305/500\n",
      "353/353 [==============================] - 0s 270us/sample - loss: 383190.2070 - mae: 93.7249 - mse: 383190.1562 - val_loss: 4129.7354 - val_mae: 7.8897 - val_mse: 4129.7354\n",
      "Epoch 306/500\n",
      "353/353 [==============================] - 0s 298us/sample - loss: 298028.0761 - mae: 102.1453 - mse: 298028.0938 - val_loss: 3238.7092 - val_mae: 7.1056 - val_mse: 3238.7090\n",
      "Epoch 307/500\n",
      "353/353 [==============================] - 0s 315us/sample - loss: 847209.3783 - mae: 128.3224 - mse: 847209.3125 - val_loss: 5518.6517 - val_mae: 8.9561 - val_mse: 5518.6519\n",
      "Epoch 308/500\n",
      "353/353 [==============================] - 0s 409us/sample - loss: 537046.4758 - mae: 109.9103 - mse: 537046.5000 - val_loss: 3501.3853 - val_mae: 7.3444 - val_mse: 3501.3853\n",
      "Epoch 309/500\n",
      "353/353 [==============================] - 0s 339us/sample - loss: 328995.8330 - mae: 100.8423 - mse: 328995.8125 - val_loss: 6069.7876 - val_mae: 9.3405 - val_mse: 6069.7881\n",
      "Epoch 310/500\n",
      "353/353 [==============================] - 0s 230us/sample - loss: 395514.8503 - mae: 108.1108 - mse: 395514.8438 - val_loss: 3297.1273 - val_mae: 7.1554 - val_mse: 3297.1272\n",
      "Epoch 311/500\n",
      "353/353 [==============================] - 0s 421us/sample - loss: 412624.6227 - mae: 105.3146 - mse: 412624.6250 - val_loss: 6907.4442 - val_mae: 9.8923 - val_mse: 6907.4438\n",
      "Epoch 312/500\n",
      "353/353 [==============================] - 0s 323us/sample - loss: 686888.6104 - mae: 124.4179 - mse: 686888.6250 - val_loss: 3572.1885 - val_mae: 7.4037 - val_mse: 3572.1885\n",
      "Epoch 313/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 617015.6927 - mae: 122.8926 - mse: 617015.6875 - val_loss: 6723.0088 - val_mae: 9.7714 - val_mse: 6723.0093\n",
      "Epoch 314/500\n",
      "353/353 [==============================] - 0s 262us/sample - loss: 517077.9291 - mae: 119.5514 - mse: 517077.9375 - val_loss: 4594.2234 - val_mae: 8.2552 - val_mse: 4594.2231\n",
      "Epoch 315/500\n",
      "353/353 [==============================] - 0s 274us/sample - loss: 357067.8333 - mae: 102.8948 - mse: 357067.8438 - val_loss: 6248.1534 - val_mae: 9.4542 - val_mse: 6248.1538\n",
      "Epoch 316/500\n",
      "353/353 [==============================] - 0s 270us/sample - loss: 383949.2349 - mae: 99.6499 - mse: 383949.1875 - val_loss: 2695.7022 - val_mae: 6.5612 - val_mse: 2695.7021\n",
      "Epoch 317/500\n",
      "353/353 [==============================] - 0s 251us/sample - loss: 921102.6119 - mae: 131.5129 - mse: 921102.6250 - val_loss: 4919.4634 - val_mae: 8.5023 - val_mse: 4919.4634\n",
      "Epoch 318/500\n",
      "353/353 [==============================] - 0s 396us/sample - loss: 512567.7258 - mae: 108.7462 - mse: 512567.7500 - val_loss: 3416.0827 - val_mae: 7.2547 - val_mse: 3416.0828\n",
      "Epoch 319/500\n",
      "353/353 [==============================] - 0s 511us/sample - loss: 312593.0345 - mae: 98.6419 - mse: 312593.0312 - val_loss: 4785.8032 - val_mae: 8.3973 - val_mse: 4785.8032\n",
      "Epoch 320/500\n",
      "353/353 [==============================] - 0s 408us/sample - loss: 346837.1139 - mae: 97.1458 - mse: 346837.0938 - val_loss: 2188.1533 - val_mae: 6.0061 - val_mse: 2188.1533\n",
      "Epoch 321/500\n",
      "353/353 [==============================] - 0s 499us/sample - loss: 538618.7494 - mae: 114.3004 - mse: 538618.7500 - val_loss: 3671.0764 - val_mae: 7.4786 - val_mse: 3671.0767\n",
      "Epoch 322/500\n",
      "353/353 [==============================] - ETA: 0s - loss: 431844.6460 - mae: 110.6785 - mse: 431844.656 - 0s 471us/sample - loss: 292851.9395 - mae: 87.8884 - mse: 292851.9375 - val_loss: 4041.3350 - val_mae: 7.7952 - val_mse: 4041.3352\n",
      "Epoch 323/500\n",
      "353/353 [==============================] - 0s 352us/sample - loss: 460914.9556 - mae: 103.4268 - mse: 460915.0000 - val_loss: 3742.1019 - val_mae: 7.5395 - val_mse: 3742.1023\n",
      "Epoch 324/500\n",
      "353/353 [==============================] - 0s 434us/sample - loss: 466482.9216 - mae: 118.4186 - mse: 466483.0000 - val_loss: 5652.3382 - val_mae: 9.0310 - val_mse: 5652.3379\n",
      "Epoch 325/500\n",
      "353/353 [==============================] - 0s 420us/sample - loss: 843416.5564 - mae: 122.8448 - mse: 843416.5625 - val_loss: 3277.6109 - val_mae: 7.1178 - val_mse: 3277.6106\n",
      "Epoch 326/500\n",
      "353/353 [==============================] - 0s 281us/sample - loss: 466885.4475 - mae: 106.8800 - mse: 466885.4375 - val_loss: 4469.8584 - val_mae: 8.1404 - val_mse: 4469.8579\n",
      "Epoch 327/500\n",
      "353/353 [==============================] - 0s 342us/sample - loss: 445888.0458 - mae: 102.6232 - mse: 445888.0000 - val_loss: 4065.4411 - val_mae: 7.8104 - val_mse: 4065.4409\n",
      "Epoch 328/500\n",
      "353/353 [==============================] - 0s 258us/sample - loss: 349021.4002 - mae: 99.6789 - mse: 349021.4062 - val_loss: 4707.2059 - val_mae: 8.3253 - val_mse: 4707.2056\n",
      "Epoch 329/500\n",
      "353/353 [==============================] - 0s 285us/sample - loss: 469379.3362 - mae: 107.2575 - mse: 469379.2500 - val_loss: 3012.0267 - val_mae: 6.8606 - val_mse: 3012.0266\n",
      "Epoch 330/500\n",
      "353/353 [==============================] - 0s 311us/sample - loss: 326425.8856 - mae: 102.5104 - mse: 326425.8750 - val_loss: 6851.2684 - val_mae: 9.8347 - val_mse: 6851.2690\n",
      "Epoch 331/500\n",
      "353/353 [==============================] - 0s 370us/sample - loss: 851046.8476 - mae: 133.7478 - mse: 851046.8125 - val_loss: 3246.9982 - val_mae: 7.0808 - val_mse: 3246.9983\n",
      "Epoch 332/500\n",
      "353/353 [==============================] - 0s 301us/sample - loss: 380339.7105 - mae: 104.6951 - mse: 380339.7188 - val_loss: 5744.5254 - val_mae: 9.0871 - val_mse: 5744.5254\n",
      "Epoch 333/500\n",
      "353/353 [==============================] - 0s 272us/sample - loss: 405067.8026 - mae: 103.5087 - mse: 405067.8438 - val_loss: 4268.3319 - val_mae: 7.9706 - val_mse: 4268.3320\n",
      "Epoch 334/500\n",
      "353/353 [==============================] - 0s 306us/sample - loss: 284722.1893 - mae: 94.4791 - mse: 284722.1875 - val_loss: 3721.6791 - val_mae: 7.5072 - val_mse: 3721.6790\n",
      "Epoch 335/500\n",
      "353/353 [==============================] - 0s 330us/sample - loss: 266980.4251 - mae: 86.3800 - mse: 266980.4062 - val_loss: 5435.4073 - val_mae: 8.8625 - val_mse: 5435.4072\n",
      "Epoch 336/500\n",
      "353/353 [==============================] - 0s 393us/sample - loss: 680439.7080 - mae: 109.9914 - mse: 680439.7500 - val_loss: 3057.8833 - val_mae: 6.8952 - val_mse: 3057.8835\n",
      "Epoch 337/500\n",
      "353/353 [==============================] - 0s 252us/sample - loss: 618707.5377 - mae: 107.4091 - mse: 618707.5625 - val_loss: 5821.4418 - val_mae: 9.1348 - val_mse: 5821.4419\n",
      "Epoch 338/500\n",
      "353/353 [==============================] - 0s 303us/sample - loss: 367205.0522 - mae: 102.3574 - mse: 367205.0625 - val_loss: 2896.3890 - val_mae: 6.7346 - val_mse: 2896.3892\n",
      "Epoch 339/500\n",
      "353/353 [==============================] - 0s 257us/sample - loss: 577736.7686 - mae: 115.1438 - mse: 577736.7500 - val_loss: 5350.5675 - val_mae: 8.7960 - val_mse: 5350.5674\n",
      "Epoch 340/500\n",
      "353/353 [==============================] - 0s 261us/sample - loss: 753484.3371 - mae: 130.1645 - mse: 753484.4375 - val_loss: 3612.6185 - val_mae: 7.4044 - val_mse: 3612.6187\n",
      "Epoch 341/500\n",
      "353/353 [==============================] - 0s 274us/sample - loss: 261625.1783 - mae: 88.8559 - mse: 261625.1562 - val_loss: 3963.5173 - val_mae: 7.7076 - val_mse: 3963.5176\n",
      "Epoch 342/500\n",
      "353/353 [==============================] - 0s 277us/sample - loss: 242686.3856 - mae: 86.5036 - mse: 242686.3906 - val_loss: 9155.7480 - val_mae: 11.1972 - val_mse: 9155.7480\n",
      "Epoch 343/500\n",
      "353/353 [==============================] - 0s 317us/sample - loss: 3660554.8689 - mae: 228.9232 - mse: 3660555.0000 - val_loss: 5236.1698 - val_mae: 8.7081 - val_mse: 5236.1699\n",
      "Epoch 344/500\n",
      "353/353 [==============================] - 0s 287us/sample - loss: 396277.1535 - mae: 96.6520 - mse: 396277.1562 - val_loss: 4082.9663 - val_mae: 7.8051 - val_mse: 4082.9663\n",
      "Epoch 345/500\n",
      "353/353 [==============================] - 0s 306us/sample - loss: 183751.0620 - mae: 81.0588 - mse: 183751.0781 - val_loss: 4558.4175 - val_mae: 8.1905 - val_mse: 4558.4175\n",
      "Epoch 346/500\n",
      "353/353 [==============================] - 0s 354us/sample - loss: 262552.7980 - mae: 91.8274 - mse: 262552.7812 - val_loss: 4323.9065 - val_mae: 8.0027 - val_mse: 4323.9067\n",
      "Epoch 347/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 248658.3107 - mae: 87.2417 - mse: 248658.3125 - val_loss: 3606.8808 - val_mae: 7.3938 - val_mse: 3606.8809\n",
      "Epoch 348/500\n",
      "353/353 [==============================] - 0s 195us/sample - loss: 643552.2556 - mae: 105.8485 - mse: 643552.2500 - val_loss: 5764.7516 - val_mae: 9.0858 - val_mse: 5764.7520\n",
      "Epoch 349/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 470778.1632 - mae: 101.3262 - mse: 470778.1875 - val_loss: 2950.7452 - val_mae: 6.7793 - val_mse: 2950.7454\n",
      "Epoch 350/500\n",
      "353/353 [==============================] - 0s 243us/sample - loss: 410957.9026 - mae: 96.9100 - mse: 410957.8750 - val_loss: 4140.1237 - val_mae: 7.8469 - val_mse: 4140.1240\n",
      "Epoch 351/500\n",
      "353/353 [==============================] - 0s 269us/sample - loss: 454465.5422 - mae: 101.0519 - mse: 454465.5000 - val_loss: 2926.8179 - val_mae: 6.7538 - val_mse: 2926.8179\n",
      "Epoch 352/500\n",
      "353/353 [==============================] - 0s 258us/sample - loss: 202246.1559 - mae: 84.9990 - mse: 202246.1719 - val_loss: 5325.7782 - val_mae: 8.7672 - val_mse: 5325.7783\n",
      "Epoch 353/500\n",
      "353/353 [==============================] - 0s 324us/sample - loss: 366334.4955 - mae: 101.2835 - mse: 366334.4688 - val_loss: 2336.0166 - val_mae: 6.1361 - val_mse: 2336.0166\n",
      "Epoch 354/500\n",
      "353/353 [==============================] - 0s 249us/sample - loss: 747487.9087 - mae: 129.2021 - mse: 747487.8750 - val_loss: 4661.2978 - val_mae: 8.2624 - val_mse: 4661.2979\n",
      "Epoch 355/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 440674.4911 - mae: 103.0284 - mse: 440674.5000 - val_loss: 2398.3747 - val_mae: 6.2019 - val_mse: 2398.3748\n",
      "Epoch 356/500\n",
      "353/353 [==============================] - 0s 440us/sample - loss: 550729.9844 - mae: 104.5994 - mse: 550730.0000 - val_loss: 5314.9169 - val_mae: 8.7553 - val_mse: 5314.9170\n",
      "Epoch 357/500\n",
      "353/353 [==============================] - 0s 297us/sample - loss: 450846.7424 - mae: 101.1224 - mse: 450846.7188 - val_loss: 2981.3980 - val_mae: 6.8010 - val_mse: 2981.3977\n",
      "Epoch 358/500\n",
      "353/353 [==============================] - 0s 218us/sample - loss: 488567.4745 - mae: 107.3763 - mse: 488567.5312 - val_loss: 5522.1720 - val_mae: 8.9036 - val_mse: 5522.1719\n",
      "Epoch 359/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 619772.4241 - mae: 111.5679 - mse: 619772.4375 - val_loss: 3815.2624 - val_mae: 7.5645 - val_mse: 3815.2622\n",
      "Epoch 360/500\n",
      "353/353 [==============================] - 0s 274us/sample - loss: 322118.8688 - mae: 91.0112 - mse: 322118.8438 - val_loss: 4173.6271 - val_mae: 7.8650 - val_mse: 4173.6270\n",
      "Epoch 361/500\n",
      "353/353 [==============================] - 0s 296us/sample - loss: 296292.1564 - mae: 92.4848 - mse: 296292.1250 - val_loss: 3028.5512 - val_mae: 6.8431 - val_mse: 3028.5513\n",
      "Epoch 362/500\n",
      "353/353 [==============================] - 0s 237us/sample - loss: 621495.7392 - mae: 115.5772 - mse: 621495.7500 - val_loss: 5189.6568 - val_mae: 8.6572 - val_mse: 5189.6567\n",
      "Epoch 363/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 613022.0833 - mae: 107.2554 - mse: 613022.1250 - val_loss: 3425.1111 - val_mae: 7.2143 - val_mse: 3425.1108\n",
      "Epoch 364/500\n",
      "353/353 [==============================] - 0s 211us/sample - loss: 329627.8297 - mae: 96.9992 - mse: 329627.8438 - val_loss: 4111.9773 - val_mae: 7.8104 - val_mse: 4111.9771\n",
      "Epoch 365/500\n",
      "353/353 [==============================] - 0s 276us/sample - loss: 240036.4545 - mae: 89.5032 - mse: 240036.4375 - val_loss: 2717.4147 - val_mae: 6.5293 - val_mse: 2717.4148\n",
      "Epoch 366/500\n",
      "353/353 [==============================] - ETA: 0s - loss: 510634.4855 - mae: 114.3590 - mse: 510634.500 - 0s 345us/sample - loss: 328100.8047 - mae: 83.1273 - mse: 328100.8125 - val_loss: 5651.3379 - val_mae: 8.9882 - val_mse: 5651.3379\n",
      "Epoch 367/500\n",
      "353/353 [==============================] - 0s 308us/sample - loss: 541373.6804 - mae: 99.3408 - mse: 541373.6250 - val_loss: 2519.9111 - val_mae: 6.3205 - val_mse: 2519.9111\n",
      "Epoch 368/500\n",
      "353/353 [==============================] - 0s 237us/sample - loss: 515074.6954 - mae: 102.0645 - mse: 515074.7500 - val_loss: 4059.4449 - val_mae: 7.7617 - val_mse: 4059.4448\n",
      "Epoch 369/500\n",
      "353/353 [==============================] - 0s 270us/sample - loss: 466025.2097 - mae: 98.7153 - mse: 466025.1875 - val_loss: 2609.8580 - val_mae: 6.4126 - val_mse: 2609.8582\n",
      "Epoch 370/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 266816.3349 - mae: 92.3186 - mse: 266816.3125 - val_loss: 5590.9670 - val_mae: 8.9408 - val_mse: 5590.9668\n",
      "Epoch 371/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 549835.4881 - mae: 110.9814 - mse: 549835.4375 - val_loss: 3863.3349 - val_mae: 7.5939 - val_mse: 3863.3350\n",
      "Epoch 372/500\n",
      "353/353 [==============================] - 0s 300us/sample - loss: 385669.6234 - mae: 92.6331 - mse: 385669.6562 - val_loss: 5784.6562 - val_mae: 9.0763 - val_mse: 5784.6562\n",
      "Epoch 373/500\n",
      "353/353 [==============================] - 0s 209us/sample - loss: 413270.2572 - mae: 97.6268 - mse: 413270.2500 - val_loss: 2656.9663 - val_mae: 6.4581 - val_mse: 2656.9663\n",
      "Epoch 374/500\n",
      "353/353 [==============================] - 0s 307us/sample - loss: 323093.7622 - mae: 92.5101 - mse: 323093.7500 - val_loss: 5880.5013 - val_mae: 9.1414 - val_mse: 5880.5015\n",
      "Epoch 375/500\n",
      "353/353 [==============================] - 0s 238us/sample - loss: 532849.1461 - mae: 113.1987 - mse: 532849.1875 - val_loss: 3263.6355 - val_mae: 7.0531 - val_mse: 3263.6355\n",
      "Epoch 376/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 379603.9971 - mae: 92.3453 - mse: 379604.0000 - val_loss: 4999.3447 - val_mae: 8.5012 - val_mse: 4999.3447\n",
      "Epoch 377/500\n",
      "353/353 [==============================] - 0s 314us/sample - loss: 459622.9278 - mae: 88.9500 - mse: 459622.9375 - val_loss: 2373.5233 - val_mae: 6.1525 - val_mse: 2373.5234\n",
      "Epoch 378/500\n",
      "353/353 [==============================] - 0s 337us/sample - loss: 430474.5032 - mae: 93.9651 - mse: 430474.5000 - val_loss: 4899.5250 - val_mae: 8.4236 - val_mse: 4899.5249\n",
      "Epoch 379/500\n",
      "353/353 [==============================] - 0s 230us/sample - loss: 470945.9789 - mae: 102.7976 - mse: 470945.9375 - val_loss: 3785.8182 - val_mae: 7.5193 - val_mse: 3785.8181\n",
      "Epoch 380/500\n",
      "353/353 [==============================] - 0s 223us/sample - loss: 349883.9941 - mae: 102.9978 - mse: 349884.0000 - val_loss: 4988.4877 - val_mae: 8.4891 - val_mse: 4988.4878\n",
      "Epoch 381/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 443494.0898 - mae: 88.6527 - mse: 443494.1250 - val_loss: 2529.7438 - val_mae: 6.3173 - val_mse: 2529.7439\n",
      "Epoch 382/500\n",
      "353/353 [==============================] - 0s 487us/sample - loss: 448690.8963 - mae: 106.4516 - mse: 448690.9062 - val_loss: 4545.0395 - val_mae: 8.1439 - val_mse: 4545.0396\n",
      "Epoch 383/500\n",
      "353/353 [==============================] - 0s 385us/sample - loss: 378435.9046 - mae: 84.9780 - mse: 378435.9062 - val_loss: 2406.7333 - val_mae: 6.1825 - val_mse: 2406.7332\n",
      "Epoch 384/500\n",
      "353/353 [==============================] - 0s 555us/sample - loss: 425555.7119 - mae: 93.7111 - mse: 425555.7188 - val_loss: 4942.0170 - val_mae: 8.4498 - val_mse: 4942.0171\n",
      "Epoch 385/500\n",
      "353/353 [==============================] - 0s 539us/sample - loss: 368042.6622 - mae: 86.3394 - mse: 368042.6875 - val_loss: 2477.7052 - val_mae: 6.2576 - val_mse: 2477.7053\n",
      "Epoch 386/500\n",
      "353/353 [==============================] - 0s 317us/sample - loss: 379493.5505 - mae: 104.5743 - mse: 379493.5625 - val_loss: 4727.8490 - val_mae: 8.2834 - val_mse: 4727.8491\n",
      "Epoch 387/500\n",
      "353/353 [==============================] - 0s 351us/sample - loss: 325712.4359 - mae: 93.9997 - mse: 325712.4375 - val_loss: 3054.6513 - val_mae: 6.8419 - val_mse: 3054.6514\n",
      "Epoch 388/500\n",
      "353/353 [==============================] - 0s 499us/sample - loss: 248927.9987 - mae: 76.3411 - mse: 248928.0000 - val_loss: 4451.1552 - val_mae: 8.0626 - val_mse: 4451.1553\n",
      "Epoch 389/500\n",
      "353/353 [==============================] - 0s 306us/sample - loss: 519479.6928 - mae: 107.4613 - mse: 519479.6250 - val_loss: 2661.8934 - val_mae: 6.4465 - val_mse: 2661.8936\n",
      "Epoch 390/500\n",
      "353/353 [==============================] - 0s 499us/sample - loss: 269817.9192 - mae: 80.8584 - mse: 269817.9062 - val_loss: 4786.8668 - val_mae: 8.3247 - val_mse: 4786.8667\n",
      "Epoch 391/500\n",
      "353/353 [==============================] - 0s 272us/sample - loss: 389609.0248 - mae: 85.5888 - mse: 389609.0312 - val_loss: 1200.3779 - val_mae: 4.6321 - val_mse: 1200.3779\n",
      "Epoch 392/500\n",
      "353/353 [==============================] - 0s 314us/sample - loss: 757793.3816 - mae: 111.0313 - mse: 757793.3750 - val_loss: 3866.6370 - val_mae: 7.5734 - val_mse: 3866.6370\n",
      "Epoch 393/500\n",
      "353/353 [==============================] - 0s 258us/sample - loss: 306284.9235 - mae: 82.2442 - mse: 306284.9375 - val_loss: 1864.4351 - val_mae: 5.5429 - val_mse: 1864.4352\n",
      "Epoch 394/500\n",
      "353/353 [==============================] - 0s 269us/sample - loss: 513121.4999 - mae: 95.0463 - mse: 513121.5938 - val_loss: 3404.2472 - val_mae: 7.1619 - val_mse: 3404.2471\n",
      "Epoch 395/500\n",
      "353/353 [==============================] - 0s 296us/sample - loss: 440444.8049 - mae: 95.2783 - mse: 440444.7812 - val_loss: 1824.1609 - val_mae: 5.4907 - val_mse: 1824.1608\n",
      "Epoch 396/500\n",
      "353/353 [==============================] - 0s 339us/sample - loss: 498217.8751 - mae: 93.7272 - mse: 498217.9375 - val_loss: 3727.3135 - val_mae: 7.4494 - val_mse: 3727.3135\n",
      "Epoch 397/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 434192.3923 - mae: 95.9598 - mse: 434192.4688 - val_loss: 2830.6462 - val_mae: 6.6105 - val_mse: 2830.6462\n",
      "Epoch 398/500\n",
      "353/353 [==============================] - 0s 315us/sample - loss: 241077.0107 - mae: 86.8141 - mse: 241077.0156 - val_loss: 4055.3377 - val_mae: 7.7282 - val_mse: 4055.3379\n",
      "Epoch 399/500\n",
      "353/353 [==============================] - 0s 340us/sample - loss: 171611.3726 - mae: 73.0549 - mse: 171611.3594 - val_loss: 1764.9386 - val_mae: 5.4121 - val_mse: 1764.9386\n",
      "Epoch 400/500\n",
      "353/353 [==============================] - 0s 512us/sample - loss: 568265.4464 - mae: 108.0847 - mse: 568265.5000 - val_loss: 4466.2383 - val_mae: 8.0630 - val_mse: 4466.2383\n",
      "Epoch 401/500\n",
      "353/353 [==============================] - 0s 590us/sample - loss: 495833.8748 - mae: 87.0812 - mse: 495833.8438 - val_loss: 2652.5629 - val_mae: 6.4248 - val_mse: 2652.5627\n",
      "Epoch 402/500\n",
      "353/353 [==============================] - 0s 379us/sample - loss: 279636.1478 - mae: 91.3653 - mse: 279636.1562 - val_loss: 4936.7736 - val_mae: 8.4282 - val_mse: 4936.7739\n",
      "Epoch 403/500\n",
      "353/353 [==============================] - 0s 342us/sample - loss: 468416.1541 - mae: 98.6908 - mse: 468416.1875 - val_loss: 3312.1281 - val_mae: 7.0691 - val_mse: 3312.1279\n",
      "Epoch 404/500\n",
      "353/353 [==============================] - 0s 378us/sample - loss: 376386.3065 - mae: 100.2756 - mse: 376386.2812 - val_loss: 4811.6708 - val_mae: 8.3302 - val_mse: 4811.6704\n",
      "Epoch 405/500\n",
      "353/353 [==============================] - 0s 432us/sample - loss: 357739.1156 - mae: 76.6084 - mse: 357739.1562 - val_loss: 2327.6819 - val_mae: 6.0724 - val_mse: 2327.6821\n",
      "Epoch 406/500\n",
      "353/353 [==============================] - 0s 388us/sample - loss: 240745.6087 - mae: 90.0266 - mse: 240745.5938 - val_loss: 4737.7346 - val_mae: 8.2708 - val_mse: 4737.7344\n",
      "Epoch 407/500\n",
      "353/353 [==============================] - 0s 450us/sample - loss: 147130.8043 - mae: 69.3867 - mse: 147130.8125 - val_loss: 1069.5541 - val_mae: 4.4079 - val_mse: 1069.5541\n",
      "Epoch 408/500\n",
      "353/353 [==============================] - 0s 382us/sample - loss: 236389.0620 - mae: 79.3914 - mse: 236389.0781 - val_loss: 3533.3909 - val_mae: 7.2647 - val_mse: 3533.3909\n",
      "Epoch 409/500\n",
      "353/353 [==============================] - 0s 306us/sample - loss: 156977.2531 - mae: 72.2930 - mse: 156977.2500 - val_loss: 4295.9735 - val_mae: 7.9154 - val_mse: 4295.9731\n",
      "Epoch 410/500\n",
      "353/353 [==============================] - 0s 513us/sample - loss: 342369.4889 - mae: 87.8061 - mse: 342369.5312 - val_loss: 4514.5093 - val_mae: 8.0889 - val_mse: 4514.5093\n",
      "Epoch 411/500\n",
      "353/353 [==============================] - 0s 319us/sample - loss: 198099.4566 - mae: 73.0080 - mse: 198099.4375 - val_loss: 1332.8145 - val_mae: 4.8081 - val_mse: 1332.8146\n",
      "Epoch 412/500\n",
      "353/353 [==============================] - 0s 375us/sample - loss: 825218.7038 - mae: 107.5701 - mse: 825218.7500 - val_loss: 3098.2944 - val_mae: 6.8547 - val_mse: 3098.2942\n",
      "Epoch 413/500\n",
      "353/353 [==============================] - 0s 285us/sample - loss: 265340.7161 - mae: 80.8459 - mse: 265340.7500 - val_loss: 1490.4710 - val_mae: 5.0307 - val_mse: 1490.4711\n",
      "Epoch 414/500\n",
      "353/353 [==============================] - 0s 230us/sample - loss: 290643.1532 - mae: 84.6073 - mse: 290643.1875 - val_loss: 4256.3636 - val_mae: 7.8774 - val_mse: 4256.3638\n",
      "Epoch 415/500\n",
      "353/353 [==============================] - 0s 320us/sample - loss: 305116.6901 - mae: 81.8745 - mse: 305116.6875 - val_loss: 1509.1331 - val_mae: 5.0553 - val_mse: 1509.1331\n",
      "Epoch 416/500\n",
      "353/353 [==============================] - 0s 234us/sample - loss: 328720.1184 - mae: 93.3724 - mse: 328720.1250 - val_loss: 4878.0600 - val_mae: 8.3679 - val_mse: 4878.0601\n",
      "Epoch 417/500\n",
      "353/353 [==============================] - 0s 297us/sample - loss: 710142.9253 - mae: 107.1276 - mse: 710142.9375 - val_loss: 3031.1671 - val_mae: 6.7868 - val_mse: 3031.1672\n",
      "Epoch 418/500\n",
      "353/353 [==============================] - 0s 260us/sample - loss: 203483.2685 - mae: 82.2506 - mse: 203483.2344 - val_loss: 4601.2351 - val_mae: 8.1512 - val_mse: 4601.2354\n",
      "Epoch 419/500\n",
      "353/353 [==============================] - 0s 308us/sample - loss: 227829.7674 - mae: 74.0023 - mse: 227829.7500 - val_loss: 2196.4634 - val_mae: 5.9098 - val_mse: 2196.4634\n",
      "Epoch 420/500\n",
      "353/353 [==============================] - 0s 253us/sample - loss: 677708.0241 - mae: 110.6068 - mse: 677707.9375 - val_loss: 3732.4071 - val_mae: 7.4288 - val_mse: 3732.4070\n",
      "Epoch 421/500\n",
      "353/353 [==============================] - 0s 238us/sample - loss: 170187.5567 - mae: 73.1732 - mse: 170187.5625 - val_loss: 1867.2871 - val_mae: 5.5170 - val_mse: 1867.2872\n",
      "Epoch 422/500\n",
      "353/353 [==============================] - 0s 357us/sample - loss: 554918.4276 - mae: 94.0174 - mse: 554918.5000 - val_loss: 3662.4707 - val_mae: 7.3660 - val_mse: 3662.4709\n",
      "Epoch 423/500\n",
      "353/353 [==============================] - 0s 250us/sample - loss: 557239.8231 - mae: 102.4586 - mse: 557239.8125 - val_loss: 2126.9755 - val_mae: 5.8269 - val_mse: 2126.9756\n",
      "Epoch 424/500\n",
      "353/353 [==============================] - 0s 307us/sample - loss: 355344.8933 - mae: 91.4824 - mse: 355344.9062 - val_loss: 3403.8110 - val_mae: 7.1319 - val_mse: 3403.8110\n",
      "Epoch 425/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 429008.1519 - mae: 86.6480 - mse: 429008.1250 - val_loss: 1569.3532 - val_mae: 5.1294 - val_mse: 1569.3530\n",
      "Epoch 426/500\n",
      "353/353 [==============================] - 0s 268us/sample - loss: 417221.3994 - mae: 88.7691 - mse: 417221.4375 - val_loss: 3682.7931 - val_mae: 7.3812 - val_mse: 3682.7932\n",
      "Epoch 427/500\n",
      "353/353 [==============================] - 0s 322us/sample - loss: 317644.7419 - mae: 87.4899 - mse: 317644.7500 - val_loss: 2940.5326 - val_mae: 6.6910 - val_mse: 2940.5325\n",
      "Epoch 428/500\n",
      "353/353 [==============================] - 0s 327us/sample - loss: 256733.4615 - mae: 77.3902 - mse: 256733.4375 - val_loss: 4361.4782 - val_mae: 7.9523 - val_mse: 4361.4780\n",
      "Epoch 429/500\n",
      "353/353 [==============================] - 0s 358us/sample - loss: 280755.2463 - mae: 79.9248 - mse: 280755.2500 - val_loss: 1409.8103 - val_mae: 4.9046 - val_mse: 1409.8103\n",
      "Epoch 430/500\n",
      "353/353 [==============================] - 0s 237us/sample - loss: 634106.7218 - mae: 98.5198 - mse: 634106.7500 - val_loss: 3256.3302 - val_mae: 6.9914 - val_mse: 3256.3303\n",
      "Epoch 431/500\n",
      "353/353 [==============================] - 0s 208us/sample - loss: 464349.1726 - mae: 86.8699 - mse: 464349.1562 - val_loss: 2254.0682 - val_mae: 5.9665 - val_mse: 2254.0681\n",
      "Epoch 432/500\n",
      "353/353 [==============================] - 0s 288us/sample - loss: 138396.5055 - mae: 68.4763 - mse: 138396.5000 - val_loss: 3949.9007 - val_mae: 7.6094 - val_mse: 3949.9006\n",
      "Epoch 433/500\n",
      "353/353 [==============================] - 0s 257us/sample - loss: 335599.8701 - mae: 80.0704 - mse: 335599.8750 - val_loss: 1535.8315 - val_mae: 5.0789 - val_mse: 1535.8314\n",
      "Epoch 434/500\n",
      "353/353 [==============================] - 0s 418us/sample - loss: 599135.6491 - mae: 86.9695 - mse: 599135.5625 - val_loss: 3678.9294 - val_mae: 7.3735 - val_mse: 3678.9294\n",
      "Epoch 435/500\n",
      "353/353 [==============================] - 0s 214us/sample - loss: 293340.2309 - mae: 78.8959 - mse: 293340.2500 - val_loss: 2320.2021 - val_mae: 6.0387 - val_mse: 2320.2021\n",
      "Epoch 436/500\n",
      "353/353 [==============================] - 0s 195us/sample - loss: 132492.4462 - mae: 69.1624 - mse: 132492.4375 - val_loss: 4242.8527 - val_mae: 7.8527 - val_mse: 4242.8530\n",
      "Epoch 437/500\n",
      "353/353 [==============================] - 0s 185us/sample - loss: 196729.8190 - mae: 76.7655 - mse: 196729.8281 - val_loss: 1691.4216 - val_mae: 5.2843 - val_mse: 1691.4215\n",
      "Epoch 438/500\n",
      "353/353 [==============================] - 0s 207us/sample - loss: 453440.5549 - mae: 104.0225 - mse: 453440.5938 - val_loss: 4711.8812 - val_mae: 8.2263 - val_mse: 4711.8813\n",
      "Epoch 439/500\n",
      "353/353 [==============================] - 0s 219us/sample - loss: 562947.0615 - mae: 95.1505 - mse: 562947.0625 - val_loss: 1028.8164 - val_mae: 4.3155 - val_mse: 1028.8164\n",
      "Epoch 440/500\n",
      "353/353 [==============================] - 0s 194us/sample - loss: 1648647.3224 - mae: 122.1235 - mse: 1648647.2500 - val_loss: 2531.4505 - val_mae: 6.2660 - val_mse: 2531.4504\n",
      "Epoch 441/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 72392.6449 - mae: 54.7915 - mse: 72392.6484 - val_loss: 2611.7720 - val_mae: 6.3502 - val_mse: 2611.7720\n",
      "Epoch 442/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 70024.3234 - mae: 56.4068 - mse: 70024.3203 - val_loss: 2202.9875 - val_mae: 5.9039 - val_mse: 2202.9875\n",
      "Epoch 443/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 255258.3236 - mae: 80.1669 - mse: 255258.3281 - val_loss: 3385.7515 - val_mae: 7.1061 - val_mse: 3385.7515\n",
      "Epoch 444/500\n",
      "353/353 [==============================] - 0s 294us/sample - loss: 488956.7828 - mae: 102.2579 - mse: 488956.7812 - val_loss: 2068.1629 - val_mae: 5.7466 - val_mse: 2068.1628\n",
      "Epoch 445/500\n",
      "353/353 [==============================] - 0s 334us/sample - loss: 111603.0549 - mae: 59.5290 - mse: 111603.0625 - val_loss: 3654.0604 - val_mae: 7.3465 - val_mse: 3654.0603\n",
      "Epoch 446/500\n",
      "353/353 [==============================] - 0s 251us/sample - loss: 153788.1655 - mae: 61.4787 - mse: 153788.1562 - val_loss: 1004.4196 - val_mae: 4.2694 - val_mse: 1004.4196\n",
      "Epoch 447/500\n",
      "353/353 [==============================] - 0s 269us/sample - loss: 258559.8641 - mae: 84.9567 - mse: 258559.8594 - val_loss: 3946.4519 - val_mae: 7.5988 - val_mse: 3946.4519\n",
      "Epoch 448/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 295068.8698 - mae: 73.1151 - mse: 295068.8438 - val_loss: 1114.6715 - val_mae: 4.4489 - val_mse: 1114.6715\n",
      "Epoch 449/500\n",
      "353/353 [==============================] - 0s 261us/sample - loss: 600505.3245 - mae: 111.3926 - mse: 600505.3125 - val_loss: 2924.7305 - val_mae: 6.6620 - val_mse: 2924.7305\n",
      "Epoch 450/500\n",
      "353/353 [==============================] - 0s 242us/sample - loss: 194763.6578 - mae: 68.8449 - mse: 194763.6719 - val_loss: 1450.7440 - val_mae: 4.9509 - val_mse: 1450.7440\n",
      "Epoch 451/500\n",
      "353/353 [==============================] - 0s 222us/sample - loss: 346802.4082 - mae: 84.2064 - mse: 346802.4375 - val_loss: 3723.3328 - val_mae: 7.4036 - val_mse: 3723.3328\n",
      "Epoch 452/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 445774.5485 - mae: 75.2212 - mse: 445774.5625 - val_loss: 1850.0388 - val_mae: 5.4768 - val_mse: 1850.0386\n",
      "Epoch 453/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 318686.6415 - mae: 68.5281 - mse: 318686.6250 - val_loss: 3222.7624 - val_mae: 6.9474 - val_mse: 3222.7622\n",
      "Epoch 454/500\n",
      "353/353 [==============================] - 0s 285us/sample - loss: 253978.1885 - mae: 71.5497 - mse: 253978.2031 - val_loss: 1325.5141 - val_mae: 4.7686 - val_mse: 1325.5142\n",
      "Epoch 455/500\n",
      "353/353 [==============================] - 0s 326us/sample - loss: 540507.7150 - mae: 85.8586 - mse: 540507.7500 - val_loss: 2761.9794 - val_mae: 6.4952 - val_mse: 2761.9792\n",
      "Epoch 456/500\n",
      "353/353 [==============================] - 0s 192us/sample - loss: 308013.9622 - mae: 75.9393 - mse: 308013.9688 - val_loss: 1296.2309 - val_mae: 4.7237 - val_mse: 1296.2310\n",
      "Epoch 457/500\n",
      "353/353 [==============================] - 0s 239us/sample - loss: 346996.6445 - mae: 89.7069 - mse: 346996.6562 - val_loss: 3272.6459 - val_mae: 6.9909 - val_mse: 3272.6458\n",
      "Epoch 458/500\n",
      "353/353 [==============================] - 0s 253us/sample - loss: 255682.9611 - mae: 83.9943 - mse: 255682.9688 - val_loss: 1987.7340 - val_mae: 5.6404 - val_mse: 1987.7339\n",
      "Epoch 459/500\n",
      "353/353 [==============================] - 0s 336us/sample - loss: 262592.3510 - mae: 87.2320 - mse: 262592.3750 - val_loss: 2949.9690 - val_mae: 6.6799 - val_mse: 2949.9690\n",
      "Epoch 460/500\n",
      "353/353 [==============================] - 0s 331us/sample - loss: 139317.7332 - mae: 61.2577 - mse: 139317.7344 - val_loss: 1035.7581 - val_mae: 4.3112 - val_mse: 1035.7581\n",
      "Epoch 461/500\n",
      "353/353 [==============================] - 0s 377us/sample - loss: 845973.5693 - mae: 94.6313 - mse: 845973.6875 - val_loss: 2617.2310 - val_mae: 6.3416 - val_mse: 2617.2310\n",
      "Epoch 462/500\n",
      "353/353 [==============================] - 0s 201us/sample - loss: 236022.9514 - mae: 74.2181 - mse: 236022.9375 - val_loss: 2102.0670 - val_mae: 5.7735 - val_mse: 2102.0671\n",
      "Epoch 463/500\n",
      "353/353 [==============================] - 0s 272us/sample - loss: 95828.9984 - mae: 61.8121 - mse: 95829.0000 - val_loss: 3064.8327 - val_mae: 6.7900 - val_mse: 3064.8328\n",
      "Epoch 464/500\n",
      "353/353 [==============================] - 0s 284us/sample - loss: 247943.2619 - mae: 78.9518 - mse: 247943.2500 - val_loss: 2239.2922 - val_mae: 5.9296 - val_mse: 2239.2922\n",
      "Epoch 465/500\n",
      "353/353 [==============================] - 0s 196us/sample - loss: 327239.3315 - mae: 88.7644 - mse: 327239.3438 - val_loss: 3446.6747 - val_mae: 7.1471 - val_mse: 3446.6748\n",
      "Epoch 466/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 104314.8134 - mae: 60.8729 - mse: 104314.8125 - val_loss: 1334.0866 - val_mae: 4.7737 - val_mse: 1334.0867\n",
      "Epoch 467/500\n",
      "353/353 [==============================] - 0s 294us/sample - loss: 118770.2067 - mae: 69.0981 - mse: 118770.1953 - val_loss: 4338.5951 - val_mae: 7.9124 - val_mse: 4338.5952\n",
      "Epoch 468/500\n",
      "353/353 [==============================] - 0s 313us/sample - loss: 676266.7229 - mae: 95.6890 - mse: 676266.6875 - val_loss: 2462.8265 - val_mae: 6.1746 - val_mse: 2462.8267\n",
      "Epoch 469/500\n",
      "353/353 [==============================] - 0s 252us/sample - loss: 306208.5998 - mae: 84.1397 - mse: 306208.5938 - val_loss: 3233.1186 - val_mae: 6.9480 - val_mse: 3233.1187\n",
      "Epoch 470/500\n",
      "353/353 [==============================] - 0s 215us/sample - loss: 126503.5559 - mae: 65.8981 - mse: 126503.5547 - val_loss: 2267.0624 - val_mae: 5.9584 - val_mse: 2267.0625\n",
      "Epoch 471/500\n",
      "353/353 [==============================] - 0s 262us/sample - loss: 249177.2229 - mae: 77.4277 - mse: 249177.2188 - val_loss: 2605.6000 - val_mae: 6.3249 - val_mse: 2605.6001\n",
      "Epoch 472/500\n",
      "353/353 [==============================] - 0s 289us/sample - loss: 334624.9489 - mae: 86.5927 - mse: 334624.9062 - val_loss: 2136.7410 - val_mae: 5.8090 - val_mse: 2136.7410\n",
      "Epoch 473/500\n",
      "353/353 [==============================] - 0s 295us/sample - loss: 198976.6984 - mae: 70.9557 - mse: 198976.7031 - val_loss: 2446.3656 - val_mae: 6.1542 - val_mse: 2446.3657\n",
      "Epoch 474/500\n",
      "353/353 [==============================] - 0s 419us/sample - loss: 117259.0455 - mae: 63.0359 - mse: 117259.0469 - val_loss: 996.5671 - val_mae: 4.2392 - val_mse: 996.5671\n",
      "Epoch 475/500\n",
      "353/353 [==============================] - 0s 224us/sample - loss: 370172.1141 - mae: 90.1316 - mse: 370172.1250 - val_loss: 3470.0039 - val_mae: 7.1649 - val_mse: 3470.0039\n",
      "Epoch 476/500\n",
      "353/353 [==============================] - 0s 251us/sample - loss: 585163.2946 - mae: 93.3093 - mse: 585163.3125 - val_loss: 2299.5756 - val_mae: 5.9925 - val_mse: 2299.5757\n",
      "Epoch 477/500\n",
      "353/353 [==============================] - 0s 194us/sample - loss: 129611.1762 - mae: 67.0405 - mse: 129611.1719 - val_loss: 3436.6689 - val_mae: 7.1339 - val_mse: 3436.6689\n",
      "Epoch 478/500\n",
      "353/353 [==============================] - 0s 217us/sample - loss: 131773.1018 - mae: 58.9400 - mse: 131773.0938 - val_loss: 919.3616 - val_mae: 4.1036 - val_mse: 919.3616\n",
      "Epoch 479/500\n",
      "353/353 [==============================] - 0s 308us/sample - loss: 426346.4122 - mae: 81.2861 - mse: 426346.3750 - val_loss: 3040.0619 - val_mae: 6.7599 - val_mse: 3040.0618\n",
      "Epoch 480/500\n",
      "353/353 [==============================] - 0s 300us/sample - loss: 512289.8657 - mae: 87.1912 - mse: 512289.8438 - val_loss: 1397.6148 - val_mae: 4.8587 - val_mse: 1397.6149\n",
      "Epoch 481/500\n",
      "353/353 [==============================] - 0s 313us/sample - loss: 356362.4551 - mae: 82.0321 - mse: 356362.4375 - val_loss: 2633.4551 - val_mae: 6.3499 - val_mse: 2633.4553\n",
      "Epoch 482/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 196079.8780 - mae: 66.8574 - mse: 196079.8906 - val_loss: 1076.2594 - val_mae: 4.3682 - val_mse: 1076.2594\n",
      "Epoch 483/500\n",
      "353/353 [==============================] - 0s 328us/sample - loss: 214026.9498 - mae: 76.2131 - mse: 214026.9531 - val_loss: 3987.7354 - val_mae: 7.6163 - val_mse: 3987.7356\n",
      "Epoch 484/500\n",
      "353/353 [==============================] - 0s 240us/sample - loss: 281409.7956 - mae: 77.8076 - mse: 281409.7812 - val_loss: 1139.4630 - val_mae: 4.4691 - val_mse: 1139.4630\n",
      "Epoch 485/500\n",
      "353/353 [==============================] - 0s 328us/sample - loss: 476919.5086 - mae: 94.1025 - mse: 476919.5312 - val_loss: 2709.9429 - val_mae: 6.4282 - val_mse: 2709.9429\n",
      "Epoch 486/500\n",
      "353/353 [==============================] - 0s 241us/sample - loss: 146820.8551 - mae: 55.5379 - mse: 146820.8438 - val_loss: 981.2827 - val_mae: 4.2088 - val_mse: 981.2827\n",
      "Epoch 487/500\n",
      "353/353 [==============================] - 0s 428us/sample - loss: 219256.0742 - mae: 78.1826 - mse: 219256.0625 - val_loss: 3522.8756 - val_mae: 7.2085 - val_mse: 3522.8757\n",
      "Epoch 488/500\n",
      "353/353 [==============================] - 0s 268us/sample - loss: 189184.0023 - mae: 68.0817 - mse: 189184.0156 - val_loss: 993.1146 - val_mae: 4.2281 - val_mse: 993.1146\n",
      "Epoch 489/500\n",
      "353/353 [==============================] - 0s 313us/sample - loss: 459117.7636 - mae: 92.0815 - mse: 459117.7812 - val_loss: 3804.1311 - val_mae: 7.4567 - val_mse: 3804.1313\n",
      "Epoch 490/500\n",
      "353/353 [==============================] - 0s 273us/sample - loss: 369949.3417 - mae: 83.4918 - mse: 369949.3438 - val_loss: 1656.5998 - val_mae: 5.2112 - val_mse: 1656.5997\n",
      "Epoch 491/500\n",
      "353/353 [==============================] - 0s 198us/sample - loss: 194697.2395 - mae: 69.7643 - mse: 194697.2500 - val_loss: 3877.6448 - val_mae: 7.5198 - val_mse: 3877.6450\n",
      "Epoch 492/500\n",
      "353/353 [==============================] - 0s 260us/sample - loss: 286366.8756 - mae: 86.2211 - mse: 286366.8750 - val_loss: 2157.3523 - val_mae: 5.8268 - val_mse: 2157.3523\n",
      "Epoch 493/500\n",
      "353/353 [==============================] - 0s 283us/sample - loss: 183206.9754 - mae: 68.5669 - mse: 183206.9688 - val_loss: 4188.6638 - val_mae: 7.7824 - val_mse: 4188.6641\n",
      "Epoch 494/500\n",
      "353/353 [==============================] - 0s 234us/sample - loss: 295471.2369 - mae: 78.0122 - mse: 295471.2188 - val_loss: 1173.0296 - val_mae: 4.5197 - val_mse: 1173.0295\n",
      "Epoch 495/500\n",
      "353/353 [==============================] - 0s 318us/sample - loss: 549652.1285 - mae: 97.8922 - mse: 549652.0625 - val_loss: 2587.3675 - val_mae: 6.2999 - val_mse: 2587.3674\n",
      "Epoch 496/500\n",
      "353/353 [==============================] - 0s 295us/sample - loss: 257903.9901 - mae: 77.9486 - mse: 257904.0000 - val_loss: 2056.1625 - val_mae: 5.7085 - val_mse: 2056.1624\n",
      "Epoch 497/500\n",
      "353/353 [==============================] - 0s 301us/sample - loss: 136463.3851 - mae: 66.8213 - mse: 136463.3906 - val_loss: 2286.0349 - val_mae: 5.9709 - val_mse: 2286.0349\n",
      "Epoch 498/500\n",
      "353/353 [==============================] - 0s 258us/sample - loss: 158604.1224 - mae: 69.9982 - mse: 158604.1406 - val_loss: 2245.8894 - val_mae: 5.9260 - val_mse: 2245.8894\n",
      "Epoch 499/500\n",
      "353/353 [==============================] - 0s 398us/sample - loss: 203595.6386 - mae: 71.2921 - mse: 203595.6562 - val_loss: 3580.7382 - val_mae: 7.2579 - val_mse: 3580.7385\n",
      "Epoch 500/500\n",
      "353/353 [==============================] - 0s 229us/sample - loss: 431421.3151 - mae: 90.4425 - mse: 431421.3125 - val_loss: 1428.9416 - val_mae: 4.8954 - val_mse: 1428.9417\n"
     ]
    }
   ],
   "source": [
    "EPOCHS =500\n",
    "\n",
    "history = dnnModel.fit(X, y,epochs=EPOCHS, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>194697.239474</td>\n",
       "      <td>69.764320</td>\n",
       "      <td>194697.250000</td>\n",
       "      <td>3877.644792</td>\n",
       "      <td>7.519834</td>\n",
       "      <td>3877.645020</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>286366.875597</td>\n",
       "      <td>86.221054</td>\n",
       "      <td>286366.875000</td>\n",
       "      <td>2157.352294</td>\n",
       "      <td>5.826784</td>\n",
       "      <td>2157.352295</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>183206.975410</td>\n",
       "      <td>68.566917</td>\n",
       "      <td>183206.968750</td>\n",
       "      <td>4188.663820</td>\n",
       "      <td>7.782372</td>\n",
       "      <td>4188.664062</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>295471.236906</td>\n",
       "      <td>78.012154</td>\n",
       "      <td>295471.218750</td>\n",
       "      <td>1173.029558</td>\n",
       "      <td>4.519740</td>\n",
       "      <td>1173.029541</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>549652.128482</td>\n",
       "      <td>97.892220</td>\n",
       "      <td>549652.062500</td>\n",
       "      <td>2587.367504</td>\n",
       "      <td>6.299891</td>\n",
       "      <td>2587.367432</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>257903.990130</td>\n",
       "      <td>77.948624</td>\n",
       "      <td>257904.000000</td>\n",
       "      <td>2056.162482</td>\n",
       "      <td>5.708506</td>\n",
       "      <td>2056.162354</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>136463.385085</td>\n",
       "      <td>66.821251</td>\n",
       "      <td>136463.390625</td>\n",
       "      <td>2286.034916</td>\n",
       "      <td>5.970903</td>\n",
       "      <td>2286.034912</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>158604.122440</td>\n",
       "      <td>69.998222</td>\n",
       "      <td>158604.140625</td>\n",
       "      <td>2245.889373</td>\n",
       "      <td>5.926014</td>\n",
       "      <td>2245.889404</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>203595.638636</td>\n",
       "      <td>71.292053</td>\n",
       "      <td>203595.656250</td>\n",
       "      <td>3580.738169</td>\n",
       "      <td>7.257926</td>\n",
       "      <td>3580.738525</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>431421.315119</td>\n",
       "      <td>90.442543</td>\n",
       "      <td>431421.312500</td>\n",
       "      <td>1428.941636</td>\n",
       "      <td>4.895414</td>\n",
       "      <td>1428.941650</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss        mae            mse     val_loss   val_mae  \\\n",
       "490  194697.239474  69.764320  194697.250000  3877.644792  7.519834   \n",
       "491  286366.875597  86.221054  286366.875000  2157.352294  5.826784   \n",
       "492  183206.975410  68.566917  183206.968750  4188.663820  7.782372   \n",
       "493  295471.236906  78.012154  295471.218750  1173.029558  4.519740   \n",
       "494  549652.128482  97.892220  549652.062500  2587.367504  6.299891   \n",
       "495  257903.990130  77.948624  257904.000000  2056.162482  5.708506   \n",
       "496  136463.385085  66.821251  136463.390625  2286.034916  5.970903   \n",
       "497  158604.122440  69.998222  158604.140625  2245.889373  5.926014   \n",
       "498  203595.638636  71.292053  203595.656250  3580.738169  7.257926   \n",
       "499  431421.315119  90.442543  431421.312500  1428.941636  4.895414   \n",
       "\n",
       "         val_mse  epoch  \n",
       "490  3877.645020    490  \n",
       "491  2157.352295    491  \n",
       "492  4188.664062    492  \n",
       "493  1173.029541    493  \n",
       "494  2587.367432    494  \n",
       "495  2056.162354    495  \n",
       "496  2286.034912    496  \n",
       "497  2245.889404    497  \n",
       "498  3580.738525    498  \n",
       "499  1428.941650    499  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAb2klEQVR4nO3deZhU1ZnH8e9LI6igRqFFZTdhCTKujSC4AKLiRofEBdwdkYdHyESjJi5RY0wcM9GMUUSH4BY3goYgrmg0UQZBbRJEkGBIg5FAQiOK24T1nT9OoWXbTVd3V9WpuvX7PE89t+reS9V7Wvh5+9S555i7IyIixa9F7AJERCQ7FOgiIgmhQBcRSQgFuohIQijQRUQSQoEuIpIQUQPdzO4xszVmtijD808zs7fMbLGZPZzr+kREionFHIduZkcCHwO/cve+DZzbA5gGDHX3981sT3dfk486RUSKQdQrdHd/GViXvs/Mvmpmz5rZfDObbWa9U4cuBO5w9/dTf1ZhLiKSphD70CcD33b3Q4DLgEmp/T2BnmY2x8zmmdnwaBWKiBSglrELSGdmbYGBwKNmtm1369S2JdADGAx0AmabWV93/yDfdYqIFKKCCnTCbwwfuPuBdRxbCcxz903AcjNbSgj41/NZoIhIoSqoLhd3/5AQ1qcCWHBA6vAMYEhqf3tCF0x1lEJFRApQ7GGLjwBzgV5mttLMLgDOBC4wszeAxUBl6vRZwHtm9hbwe+Byd38vRt0iIoUo6rBFERHJnoLqchERkaaL9qVo+/btvVu3brE+XkSkKM2fP3+tu5fXdSxaoHfr1o2qqqpYHy8iUpTM7J36jqnLRUQkIRToIiIJoUAXEUkIBbqISEIo0EVEEkKBLiKSEAp0EZGEKL5AX7QILrsMPvkkdiUiIgWl+AJ9xQq45RbQTUkiIl9QfIF+2GFhO2dO3DpERApM8QV6u3bQuze88krsSkRECkrxBTrAwIEwdy5s3Rq7EhGRglGcgT5oEKxbB0uXxq5ERKRgFGegDxwYtrNnx61DRKSAFGeg9+oFHTvC734XuxIRkYJRnIFuBsceGwJ9y5bY1YiIFITiDHQIgf7++zB/fuxKREQKQvEG+rBh4Up91qzYlYiIFIQGA93M7jGzNWa2qJ7jZ5rZwtTjFTM7IPtl1qF9e+jXD2bOzMvHiYgUukyu0O8Dhm/n+HLgKHffH7gBmJyFujLzrW+FKQDeqXeJPRGRktFgoLv7y8C67Rx/xd3fT72cB3TKUm0NO/nksH3++bx9pIhIocp2H/oFwDP1HTSzsWZWZWZVNTU1zf+03r1hr73g979v/nuJiBS5rAW6mQ0hBPr36zvH3Se7e4W7V5SXl2fjQ2Hw4BDo7s1/PxGRIpaVQDez/YEpQKW7v5eN98zYkCGwejW8/XZeP1ZEpNA0O9DNrAswHTjb3fOfqkOGhO1zz+X9o0VECkkmwxYfAeYCvcxspZldYGbjzGxc6pRrgXbAJDNbYGb5XXnia1+Dvn3hoYfy+rEiIoWmZUMnuPvoBo6PAcZkraLGMoNzz4XLLw+rGXXrFq0UEZGYivdO0XTbhi8+U+8AGxGRxEtGoPfsCd27K9BFpKQlI9DNYPhwePFF2LAhdjUiIlEkI9ABTjgBPvlENxmJSMlKTqAfcwzsvjvcf3/sSkREokhOoLduDaefHmZfVLeLiJSg5AQ6hH70Tz+FuXNjVyIiknfJCvQhQ6CsTHeNikhJSlag77orHHaYptMVkZKUrECHsNbo/PmQjel5RUSKSPICffjwMJWuul1EpMQkL9APOQTKy+HJJ2NXIiKSV8kL9BYtYOTIMHzx449jVyMikjfJC3SAs88Owxcffzx2JSIieZPMQB84MKw1qkAXkRKSzEBv0SJMqfvMM7prVERKRjIDHaCyMvSha7IuESkRyQ30oUOhTRt47LHYlYiI5EVyA32nneCb3wyB/q9/xa5GRCTnkhvoAGecAevXwwsvxK5ERCTnkh3oQ4ZA27ZhTLqISMIlO9Bbtw5TATzxBGzdGrsaEZGcajDQzeweM1tjZovqOW5mdpuZLTOzhWZ2cPbLbIYRI2D16jBhl4hIgmVyhX4fMHw7x48HeqQeY4E7m19WFp1wQhiXrm4XEUm4BgPd3V8G1m3nlErgVx7MA75iZntnq8Bma9cODj9cgS4iiZeNPvSOwLtpr1em9n2JmY01syozq6rJ53zlI0bAwoWwYkX+PlNEJM+yEehWxz6v60R3n+zuFe5eUV5enoWPztCIEWGrq3QRSbBsBPpKoHPa607Aqiy8b/b06AH77w/33hsWvxARSaBsBPpM4JzUaJcBwHp3X52F982u8eNhwQKoqopdiYhITmQybPERYC7Qy8xWmtkFZjbOzMalTnkaqAaWAb8ELspZtc0xcmTYzpoVtw4RkRwxj9QFUVFR4VX5vlo+5BDYYQeYNy+/nysikiVmNt/dK+o6luw7RWs7+2x49VUFuogkUmkF+pgxsOOO8MgjsSsREcm60gr0tm3DPOlPPaXRLiKSOKUV6BBWMvrrXzW3i4gkTukF+umnh8Uv7rsvdiUiIllVeoG+224wbFhYQFpEJEFKL9ABjjkGqqth2bLYlYiIZE1pBvqIEVBWBpMmxa5ERCRrSjPQu3YNfel3360FpEUkMUoz0AHOOQc+/FB96SKSGKUb6EcfDeXluslIRBKjdAO9ZUs49dSwgPRHH8WuRkSk2Uo30AFGjw596I8/HrsSEZFmK+1AHzgQunSBhx+OXYmISLOVdqC3aAFnnRXmSF9deGtyiIg0RmkHOsC558LWrfDgg7ErERFpFgV6z56h6+W++zQDo4gUNQU6wHnnwVtvab1RESlqCnSA004LMzBOnhy7EhGRJlOgQ5iB8ayzQj/6++/HrkZEpEkU6NtccEEYk/7007ErERFpEgX6Nv36QYcOMGNG7EpERJoko0A3s+FmttTMlpnZFXUc383MnjCzN8xssZmdn/1Sc6xFi9CXPnMmrF0buxoRkUZrMNDNrAy4Azge6AOMNrM+tU4bD7zl7gcAg4FbzKxVlmvNvbFjYeNGuPPO2JWIiDRaJlfohwLL3L3a3TcCU4HKWuc4sIuZGdAWWAdszmql+dC3b1j84r//W/Oki0jRySTQOwLvpr1emdqXbiLwdWAV8CbwHXffWvuNzGysmVWZWVVNTU0TS86x8ePDSBd9OSoiRSaTQLc69tW+pfI4YAGwD3AgMNHMdv3SH3Kf7O4V7l5RXl7e6GLzYuhQ2GsveOCB2JWIiDRKJoG+Euic9roT4Uo83fnAdA+WAcuB3tkpMc9atgzT6j71FKxbF7saEZGMZRLorwM9zKx76ovOUcDMWuf8DTgawMw6AL2A6mwWmldnnw2bNsGjj8auREQkYw0GurtvBiYAs4AlwDR3X2xm48xsXOq0G4CBZvYm8ALwfXcv3rF/Bx4Iffqo20VEikrLTE5y96eBp2vtuyvt+Srg2OyWFpFZuEq/8kqoroZ9941dkYhIg3SnaH3OOCME+z33xK5ERCQjCvT6dOkCJ58cZmDUmHQRKQIK9O35j/+AmhqYOjV2JSIiDVKgb8/QodCrF9x7b+xKREQapEDfHrMwJn32bLj8cnjttdgViYjUS4HekLFj4cgj4bbbYMAAXa2LSMFSoDdk773hD38IfemDB8PFF4fnIiIFRoGeqV13hUmT4JNP4Ic/jF2NiMiXKNAbo3dvGDMGpkyB996LXY2IyBco0Btr/PiwCIamBRCRAqNAb6x/+zfo3x9++Uvw2rMIi4jEo0BvijFj4K23YO7c2JWIiHxGgd4Uo0ZB27YwcWLsSkREPqNAb4q2bWHCBHjkEV2li0jBUKA31Q9+EIYy3nVXw+eKiOSBAr2p2rQJXS+PPQYffRS7GhERBXqznH8+fPop/PrXsSsREVGgN0v//mG5up/8BDZsiF2NiJQ4BXpzmMENN8CKFfDUU7GrEZESp0BvruHDoUMHuO++2JWISIlToDdXy5Zhit0nnoA33ohdjYiUMAV6NlxySRjCqFkYRSSijALdzIab2VIzW2ZmV9RzzmAzW2Bmi83speyWWeB23x2+8x2YMQOWL49djYiUqAYD3czKgDuA44E+wGgz61PrnK8Ak4AR7r4fcGoOai1sF14YviS9++7YlYhIicrkCv1QYJm7V7v7RmAqUFnrnDOA6e7+NwB3X5PdMotA584wciT84hewdm3sakSkBGUS6B2Bd9Ner0ztS9cT2N3M/mBm883snLreyMzGmlmVmVXVJHEZtx/9CD7+OCyAISKSZ5kEutWxr/ZE4C2BQ4ATgeOAa8ys55f+kPtkd69w94ry8vJGF1vw9tsPjj4a7rwTNm+OXY2IlJhMAn0l0DntdSdgVR3nPOvun7j7WuBl4IDslFhkJkyAv/0NHn88diUiUmIyCfTXgR5m1t3MWgGjgJm1znkcOMLMWprZzkB/YEl2Sy0SJ50EPXqE7petW2NXIyIlpMFAd/fNwARgFiGkp7n7YjMbZ2bjUucsAZ4FFgKvAVPcfVHuyi5gLVuG8egLF4aZGEVE8sQ80rqYFRUVXlVVFeWzc27LFjjggNCPvmhRCHkRkSwws/nuXlHXMd0pmgtlZaHLZelSePjh2NWISIlQoOfKyJFw8MHw4x9DpN+CRKS0KNBzxQwuvhj+8heYPTt2NSJSAhToufTNb8Iee8BVV+kqXURyToGeS23awE03wZw58MwzsasRkYRToOfauedCp07hKl3L1IlIDinQc61VK7j99rD4hVY1EpEcUqDnQ2Ul7L8/TJwImzbFrkZEEkqBng9mcM014Sajm2+OXY2IJJQCPV9OOSXM83LzzWGKXRGRLFOg59PVV8O6dfA//xO7EhFJIAV6Pg0YAMOGwY03QhIX+BCRqBTo+XbrrfDBB/DTn8auREQSRoGeb/vtB2ecAZMmhYUwRESyRIEew7YJuy6/PHYlIpIgCvQYunaFK66AadNg3rzY1YhIQijQY7n00jBx17XXauIuEckKBXosbdvCddfB88/D/ffHrkZEEkCBHtOECXDEEWHe9LVrY1cjIkVOgR5TixZw113w0UdhbLqISDMo0GPr0wfOOw/uuAPeeSd2NSJSxDIKdDMbbmZLzWyZmV2xnfP6mdkWMzsleyWWgB/+MEzg9YMfxK5ERIpYg4FuZmXAHcDxQB9gtJn1qee8nwKzsl1k4nXuDJddBg8+CNOnx65GRIpUJlfohwLL3L3a3TcCU4HKOs77NvAbYE0W6ysd114L/frBmDGa50VEmiSTQO8IvJv2emVq32fMrCMwErhre29kZmPNrMrMqmoUWl/UqlVY0Wj9erj++tjViEgRyiTQrY59te+EuRX4vrtv2d4buftkd69w94ry8vJMaywdffrARReFeV7mzo1djYgUmUwCfSXQOe11J2BVrXMqgKlmtgI4BZhkZt/ISoWl5qabYK+94JJLYPPm2NWISBHJJNBfB3qYWXczawWMAmamn+Du3d29m7t3Ax4DLnL3GVmvthS0aQO33AKvvgo/+1nsakSkiDQY6O6+GZhAGL2yBJjm7ovNbJyZjct1gSVp9Gj4xjfCzUYamy4iGTKPNDFURUWFV1VVRfnsolBdDQceCH37wksvwQ47xK5IRAqAmc1394q6julO0UK1774weXL4clSrG4lIBhTohWzUKDjtNLjhBliyJHY1IlLgFOiF7rbbwlS7p5wCH38cuxoRKWAK9ELXoUNY2WjJErj66tjViEgBU6AXg6OPhvHj4fbbdcORiNRLgV4sbrwROnUKU+2uXh27GhEpQAr0YrHLLvDAA/D3v8PIkbqLVES+RIFeTI46Cu6+O9xF+pOfxK5GRAqMAr3YnH46nHVWWBRj6tTY1YhIAVGgF6MpU2DQIBg7NtxRKiKCAr04tW4NDz0EZWWhP/3DD2NXJCIFQIFerLp2hV//Gt56K9x0tGlT7IpEJDIFejE79tgw38vzz4ful0gTrYlIYWgZuwBppvPPD1PsXn899OgBV10VuyIRiURX6Elw3XVhIq/rroMXX4xdjYhEokBPAjOYODFcoZ98cuhXF5GSo0BPinbt4He/C0vYHXkkLF8euyIRyTMFepLssw/Mng0bN8JJJ2n5OpESo0BPml69YPr0MOfLiSfC+vWxKxKRPFGgJ9GwYSHUly6FIUNg7drYFYlIHijQk2roUJgxI3xBeuKJUFMTuyIRyTEFepKdeGK4m3ThwjD3y6pVsSsSkRzKKNDNbLiZLTWzZWZ2RR3HzzSzhanHK2Z2QPZLlSaprAyjX1avDl0x//hH7IpEJEcaDHQzKwPuAI4H+gCjzaxPrdOWA0e5+/7ADcDkbBcqzTBoEDz5ZBj1cvjhGtIoklCZXKEfCixz92p33whMBSrTT3D3V9z9/dTLeUCn7JYpzXbUUfDCC7BuXQj1RYtiVyQiWZZJoHcE3k17vTK1rz4XAM/UdcDMxppZlZlV1ehLuvwbMABefjlM4nXkkTBvXuyKRCSLMgl0q2NfndP6mdkQQqB/v67j7j7Z3SvcvaK8vDzzKiV7+vaFOXNgjz1CqE+cGLsiEcmSTAJ9JdA57XUn4EvDJcxsf2AKUOnu72WnPMmJ7t3D1fnw4fDtb8Oll4a7S0WkqGUS6K8DPcysu5m1AkYBM9NPMLMuwHTgbHd/O/tlSta1bw+//S1MmAA//zkMHqy7SkWKXIOB7u6bgQnALGAJMM3dF5vZODMblzrtWqAdMMnMFphZVc4qluwpK4Pbbw+LTb/+Ohx2GLz5ZuyqRKSJzCOtclNRUeFVVcr9gvHii3DmmfDBB3DbbTBmTJiWV0QKipnNd/eKuo7pTlEJhg6FBQvgiCPCcnZnnAEffRS7KhFpBAW6fK5DB3j2WbjxRpg2LQxz1GIZIkVDgS5f1KIFXHllWHi6pgYOPhh+9jPYsiV2ZSLSAAW61G3o0PAF6QknwPe+BwMH6u5SkQKnQJf6degAv/kNPPwwVFeHq/XrroMNG2JXJiJ1UKDL9pnB6NGwZAmcfjr86Edw0EFhCgERKSgKdMlM+/bwwAPw9NPwySdhsq/TTtPMjSIFRIEujXP88eFq/frr4amn4Otfh6uu0hBHkQKgQJfG23lnuPbasGbpqafCf/4n9OwJ994LW7fGrk6kZCnQpek6dQrdMPPmQbdu8O//Dv36wUsvxa5MpCQp0KX5+veHV14Jo2HWrAkTfQ0bBv/7v7ErEykpCnTJjm2jYd5+O8zeuGhRmEZgyBCYPh02b45doUjiKdAlu3baCS65JIxbv+WWsP3Wt8Ic7D/+Mfzzn7ErFEksBbrkxs47w3e/GwJ9xowwGuaaa6Bz5zDx15w5YSk8EckaBbrkVlkZVFbCc8+FUTEXXRTGsh9+OOy3X5gIbMWK2FWKJIICXfKnZ0+49Vb4+99h8uRws9LVV4fumP794eabFe4izaBAl/xr0wYuvDBMH7B8Odx0U5jN8fLLQ7j36xf2LVyobhmRRtCKRVI4qqvDZGCPPhqWxAPYZx847rjwOProcFUvUsK2t2KRAl0K06pVMGsWPPNMmJv9gw/C0MiDDgr974MGhUfHjrErFckrBboUty1boKoqfLH64ovw6qvwf/8XjnXtGlZWGjAAKirggANgl13i1iuSQwp0SZZNm8L6p3PmhMerr8K774ZjZvC1r8GBB37+6NMHunQJqzGJFDkFuiTfqlXwxz+GoP/Tn8K2uvrz4zvuCL16Qe/eYdu9e5h/pnv30G3TsmW00kUaY3uBntHfYjMbDvwCKAOmuPtNtY5b6vgJwKfAee7+x2ZVLdIY++wTHied9Pm+9evDMnp//vPnj6qq8KVr+qyQZWXhhqdtId+lC+y1F+y5Z3h06BC2u+4afgMQKVANBrqZlQF3AMcAK4HXzWymu6cvB3880CP16A/cmdqKxLPbbuEL1MMP/+L+jRtDF82KFWHYZPr22Wdh9eq636916y8GfIcOYdTNbruFsK/9aNs2TIWw885hu9NO+k1AciqTv12HAsvcvRrAzKYClUB6oFcCv/LQfzPPzL5iZnu7ez3/MkQiatUKvvrV8KjLpk1QUxNmjlyzJsw/U3v7j3/AG2/A2rWNW2O1rCz8j2HHHT/ftmqVnXblgn4jyY0xY+DSS7P+tpkEekfg3bTXK/ny1Xdd53QEvhDoZjYWGAvQpUuXxtYqkh877PB5F04mNm4MKzZ9+OHnj/Xrw1J9n34aRuRs227YAP/61xe3GzYUZnDqpq7c2XvvnLxtJoFe19+02v+lMzkHd58MTIbwpWgGny1S+Fq1gnbtwkMkokzGca0EOqe97gSsasI5IiKSQ5kE+utADzPrbmatgFHAzFrnzATOsWAAsF795yIi+dVgl4u7bzazCcAswrDFe9x9sZmNSx2/C3iaMGRxGWHY4vm5K1lEROqS0Rgqd3+aENrp++5Ke+7A+OyWJiIijaF7oUVEEkKBLiKSEAp0EZGEUKCLiCREtNkWzawGeKeJf7w9sDaL5RQDtbk0qM2loTlt7uru5XUdiBbozWFmVfVNH5lUanNpUJtLQ67arC4XEZGEUKCLiCREsQb65NgFRKA2lwa1uTTkpM1F2YcuIiJfVqxX6CIiUosCXUQkIYou0M1suJktNbNlZnZF7HqyxczuMbM1ZrYobd8eZva8mf0ltd097diVqZ/BUjM7Lk7VzWNmnc3s92a2xMwWm9l3UvsT224z29HMXjOzN1Jtvj61P7FthrA2sZn9ycyeTL1OdHsBzGyFmb1pZgvMrCq1L7ftdveieRCm7/0rsC/QCngD6BO7riy17UjgYGBR2r7/Aq5IPb8C+GnqeZ9U21sD3VM/k7LYbWhCm/cGDk493wV4O9W2xLabsLpX29TzHYBXgQFJbnOqHd8FHgaeTL1OdHtTbVkBtK+1L6ftLrYr9M8WrHb3jcC2BauLnru/DKyrtbsSuD/1/H7gG2n7p7r7BndfTpiH/tC8FJpF7r7a3f+Yev4RsISwFm1i2+3Bx6mXO6QeToLbbGadgBOBKWm7E9veBuS03cUW6PUtRp1UHTy18lNqu2dqf+J+DmbWDTiIcMWa6Hanuh8WAGuA59096W2+FfgesDVtX5Lbu40Dz5nZfDMbm9qX03ZntMBFAcloMeoSkKifg5m1BX4DXOzuH5rV1bxwah37iq7d7r4FONDMvgL81sz6buf0om6zmZ0ErHH3+WY2OJM/Use+omlvLYPcfZWZ7Qk8b2Z/3s65WWl3sV2hl9pi1P80s70BUts1qf2J+TmY2Q6EMH/I3aendie+3QDu/gHwB2A4yW3zIGCEma0gdJEONbMHSW57P+Puq1LbNcBvCV0oOW13sQV6JgtWJ8lM4NzU83OBx9P2jzKz1mbWHegBvBahvmaxcCl+N7DE3X+ediix7Taz8tSVOWa2EzAM+DMJbbO7X+nundy9G+Hf64vufhYJbe82ZtbGzHbZ9hw4FlhErtsd+5vgJnxzfAJhNMRfgatj15PFdj0CrAY2Ef5vfQHQDngB+Etqu0fa+VenfgZLgeNj19/ENh9O+LVyIbAg9Tghye0G9gf+lGrzIuDa1P7EtjmtHYP5fJRLottLGIn3RuqxeFtW5brduvVfRCQhiq3LRURE6qFAFxFJCAW6iEhCKNBFRBJCgS4ikhAKdBGRhFCgi4gkxP8D39VTQpa8DrUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['mae'],color='red')\n",
    "plt.show()\n",
    "plt.plot(hist['val_mae'],color='green')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
